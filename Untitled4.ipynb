{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a9c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from typing import List, Tuple, Set, Any, Optional\n",
    "from nltk import ngrams\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from light_scenario import LightInstance, LightScenario, LightScenarioKey\n",
    "from light_tokenizer import LightTokenizer, DefaultTokenizer\n",
    "from load_documents import get_document_iterator\n",
    "from data_overlap_stats import (\n",
    "    DataOverlapStats,\n",
    "    DataOverlapStatsKey,\n",
    "    PART_INPUT,\n",
    "    PART_REF,\n",
    ")\n",
    "from common.hierarchical_logger import hlog, htrack_block\n",
    "from common.general import asdict_without_nones, write\n",
    "from scenarios.scenario import ScenarioSpec\n",
    "\n",
    "\n",
    "# The n values of the ngrams to be computed\n",
    "N_VALUES: List[int] = [5, 9, 13]  # TODO: Pick the N values\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EntryDataOverlapKey:\n",
    "    \"\"\"Unique key representing either the input or references of a single instance in a scenario.\"\"\"\n",
    "\n",
    "    stats_key: DataOverlapStatsKey\n",
    "    part: str\n",
    "    \"\"\"Either PART_INPUT or PART_REF\"\"\"\n",
    "    instance_id: int\n",
    "\n",
    "\n",
    "# type alias for overlap-related data structures\n",
    "Ngram = Tuple[str, ...]\n",
    "NgramIndex = Dict[int, Dict[Ngram, Set[EntryDataOverlapKey]]]\n",
    "AllDataOverlapStats = Dict[DataOverlapStatsKey, DataOverlapStats]\n",
    "NgramCounter = Dict[EntryDataOverlapKey, Dict[Ngram, int]]\n",
    "\n",
    "\n",
    "def load_light_scenarios_from_jsonl(path: str) -> List[LightScenario]:\n",
    "    \"\"\"\n",
    "    Create a list of light scenarios from a jsonl file, where each json represents a LightScenario object.\n",
    "\n",
    "    Input file format:\n",
    "\n",
    "    Instance JSON 1\n",
    "    Instance JSON 2\n",
    "    Instance JSON 3\n",
    "    ...\n",
    "\n",
    "    Each line is a json and each json looks like:\n",
    "    {\n",
    "        \"light_scenario_key\": {\n",
    "            \"metadata\":{\n",
    "                \"split\": \"SPLIT\",\n",
    "                \"scenario_attribute_1\": \"ATTRIBUTE1\",\n",
    "                \"scenario_attribute_2\": \"ATTRIBUTE2\",\n",
    "            }\n",
    "        },\n",
    "        \"light_instances\": [\n",
    "            {\n",
    "                \"input\": \"INPUT_TEXT1\",\n",
    "                \"references\": [\n",
    "                    \"REFERENCE_TEXT_1\",\n",
    "                    \"REFERENCE_TEXT_2\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"INPUT_TEXT2\",\n",
    "                \"references\": [\n",
    "                    \"REFERENCE_TEXT_3\",\n",
    "                    \"REFERENCE_TEXT_4\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    Note that the values of light_scenario_key.metadata need to be hashable.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_light_instance_from_dict(instance_dict: dict) -> LightInstance:\n",
    "        return LightInstance(input=instance_dict[\"input\"], references=instance_dict[\"references\"])\n",
    "\n",
    "    light_scenarios: List[LightScenario] = []\n",
    "    light_scenario_jsons = open(path, \"r\").readlines()\n",
    "    for light_scenario_json in light_scenario_jsons:\n",
    "        light_scenario_dict: dict = json.loads(light_scenario_json)\n",
    "\n",
    "        light_scenario_metadata: dict = light_scenario_dict[\"light_scenario_key\"][\"metadata\"]\n",
    "        # if the light_scenarios are exported from helm, they will have a scenario_spec field\n",
    "        if \"scenario_spec\" in light_scenario_metadata:\n",
    "            light_scenario_metadata[\"scenario_spec\"] = ScenarioSpec(**light_scenario_metadata[\"scenario_spec\"])\n",
    "        light_scenario_key = LightScenarioKey(metadata=light_scenario_metadata)\n",
    "        light_instances: List[LightInstance] = [\n",
    "            create_light_instance_from_dict(instance_dict) for instance_dict in light_scenario_dict[\"light_instances\"]\n",
    "        ]\n",
    "        light_scenarios.append(LightScenario(light_scenario_key=light_scenario_key, light_instances=light_instances))\n",
    "    return light_scenarios\n",
    "light_scenarios = load_light_scenarios_from_jsonl('05_30_23_scenario_data.jsonl')\n",
    "scenario_keys = []\n",
    "for light_scenario in light_scenarios:\n",
    "    scenario_keys.append(light_scenario.light_scenario_key)\n",
    "# from common.general import asdict_without_nones\n",
    "# with open('05_30_23_scenario_data.jsonl_keys2', \"w\") as f:\n",
    "#     f.writelines(f\"{json.dumps(asdict_without_nones(scenario_key))}\\n\" for scenario_key in scenario_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d880838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scenario_spec': ScenarioSpec(class_name='helm.benchmark.scenarios.math_scenario.MATHScenario', args={'subject': 'algebra', 'level': 3, 'use_official_examples': True, 'use_chain_of_thought': False}), 'split': 'test'}\n",
      "ScenarioSpec(class_name='helm.benchmark.scenarios.math_scenario.MATHScenario', args={'subject': 'algebra', 'level': 3, 'use_official_examples': True, 'use_chain_of_thought': False})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scenario_keys[0].metadata)\n",
    "print(scenario_keys[0].metadata['scenario_spec'])\n",
    "scenario_keys[0].metadata['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e4299a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_keys[0].metadata['scenario_spec']\n",
    "from common.general import asdict_without_nones\n",
    "with open('05_30_23_scenario_data.jsonl_keys3_scenario_spec_plus_split', \"w\") as f:\n",
    "    for scenario_key in scenario_keys:\n",
    "        f.write(f\"{json.dumps(asdict_without_nones(scenario_key.metadata['scenario_spec']))}; {scenario_key.metadata['split']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7f30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_scenarios = load_light_scenarios_from_jsonl('scenario_data_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a817b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_scenarios = load_light_scenarios_from_jsonl('scenario_data_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "001c2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_keys = []\n",
    "for light_scenario in light_scenarios:\n",
    "    scenario_keys.append(light_scenario.light_scenario_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6e43bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.general import asdict_without_nones\n",
    "with open('testout', \"w\") as f:\n",
    "    f.writelines(f\"{json.dumps(asdict_without_nones(scenario_key))}\\n\" for scenario_key in scenario_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d41b8bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'run_specs_filtered'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m         light_scenarios\u001b[38;5;241m.\u001b[39mappend(LightScenario(light_scenario_key\u001b[38;5;241m=\u001b[39mlight_scenario_key, light_instances\u001b[38;5;241m=\u001b[39mlight_instances))\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m light_scenarios\n\u001b[0;32m--> 106\u001b[0m light_scenarios \u001b[38;5;241m=\u001b[39m \u001b[43mload_light_scenarios_from_jsonl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_specs_filtered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m scenario_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m light_scenario \u001b[38;5;129;01min\u001b[39;00m light_scenarios:\n",
      "Cell \u001b[0;32mIn[15], line 92\u001b[0m, in \u001b[0;36mload_light_scenarios_from_jsonl\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LightInstance(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minstance_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m], references\u001b[38;5;241m=\u001b[39minstance_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreferences\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     91\u001b[0m light_scenarios: List[LightScenario] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 92\u001b[0m light_scenario_jsons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m light_scenario_json \u001b[38;5;129;01min\u001b[39;00m light_scenario_jsons:\n\u001b[1;32m     94\u001b[0m     light_scenario_dict: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(light_scenario_json)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'run_specs_filtered'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from typing import List, Tuple, Set, Any, Optional\n",
    "from nltk import ngrams\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from light_scenario import LightInstance, LightScenario, LightScenarioKey\n",
    "from light_tokenizer import LightTokenizer, DefaultTokenizer\n",
    "from load_documents import get_document_iterator\n",
    "from data_overlap_stats import (\n",
    "    DataOverlapStats,\n",
    "    DataOverlapStatsKey,\n",
    "    PART_INPUT,\n",
    "    PART_REF,\n",
    ")\n",
    "from common.hierarchical_logger import hlog, htrack_block\n",
    "from common.general import asdict_without_nones, write\n",
    "from scenarios.scenario import ScenarioSpec\n",
    "\n",
    "\n",
    "# The n values of the ngrams to be computed\n",
    "N_VALUES: List[int] = [5, 9, 13]  # TODO: Pick the N values\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EntryDataOverlapKey:\n",
    "    \"\"\"Unique key representing either the input or references of a single instance in a scenario.\"\"\"\n",
    "\n",
    "    stats_key: DataOverlapStatsKey\n",
    "    part: str\n",
    "    \"\"\"Either PART_INPUT or PART_REF\"\"\"\n",
    "    instance_id: int\n",
    "\n",
    "\n",
    "# type alias for overlap-related data structures\n",
    "Ngram = Tuple[str, ...]\n",
    "NgramIndex = Dict[int, Dict[Ngram, Set[EntryDataOverlapKey]]]\n",
    "AllDataOverlapStats = Dict[DataOverlapStatsKey, DataOverlapStats]\n",
    "NgramCounter = Dict[EntryDataOverlapKey, Dict[Ngram, int]]\n",
    "\n",
    "\n",
    "def load_light_scenarios_from_jsonl(path: str) -> List[LightScenario]:\n",
    "    \"\"\"\n",
    "    Create a list of light scenarios from a jsonl file, where each json represents a LightScenario object.\n",
    "\n",
    "    Input file format:\n",
    "\n",
    "    Instance JSON 1\n",
    "    Instance JSON 2\n",
    "    Instance JSON 3\n",
    "    ...\n",
    "\n",
    "    Each line is a json and each json looks like:\n",
    "    {\n",
    "        \"light_scenario_key\": {\n",
    "            \"metadata\":{\n",
    "                \"split\": \"SPLIT\",\n",
    "                \"scenario_attribute_1\": \"ATTRIBUTE1\",\n",
    "                \"scenario_attribute_2\": \"ATTRIBUTE2\",\n",
    "            }\n",
    "        },\n",
    "        \"light_instances\": [\n",
    "            {\n",
    "                \"input\": \"INPUT_TEXT1\",\n",
    "                \"references\": [\n",
    "                    \"REFERENCE_TEXT_1\",\n",
    "                    \"REFERENCE_TEXT_2\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"INPUT_TEXT2\",\n",
    "                \"references\": [\n",
    "                    \"REFERENCE_TEXT_3\",\n",
    "                    \"REFERENCE_TEXT_4\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    Note that the values of light_scenario_key.metadata need to be hashable.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_light_instance_from_dict(instance_dict: dict) -> LightInstance:\n",
    "        return LightInstance(input=instance_dict[\"input\"], references=instance_dict[\"references\"])\n",
    "\n",
    "    light_scenarios: List[LightScenario] = []\n",
    "    light_scenario_jsons = open(path, \"r\").readlines()\n",
    "    for light_scenario_json in light_scenario_jsons:\n",
    "        light_scenario_dict: dict = json.loads(light_scenario_json)\n",
    "\n",
    "        light_scenario_metadata: dict = light_scenario_dict[\"light_scenario_key\"][\"metadata\"]\n",
    "        # if the light_scenarios are exported from helm, they will have a scenario_spec field\n",
    "        if \"scenario_spec\" in light_scenario_metadata:\n",
    "            light_scenario_metadata[\"scenario_spec\"] = ScenarioSpec(**light_scenario_metadata[\"scenario_spec\"])\n",
    "        light_scenario_key = LightScenarioKey(metadata=light_scenario_metadata)\n",
    "        light_instances: List[LightInstance] = [\n",
    "            create_light_instance_from_dict(instance_dict) for instance_dict in light_scenario_dict[\"light_instances\"]\n",
    "        ]\n",
    "        light_scenarios.append(LightScenario(light_scenario_key=light_scenario_key, light_instances=light_instances))\n",
    "    return light_scenarios\n",
    "light_scenarios = load_light_scenarios_from_jsonl('run_specs_filtered')\n",
    "scenario_keys = []\n",
    "for light_scenario in light_scenarios:\n",
    "    scenario_keys.append(light_scenario.light_scenario_key)\n",
    "from common.general import asdict_without_nones\n",
    "with open('run_specs_filtered_keys', \"w\") as f:\n",
    "    f.writelines(f\"{json.dumps(asdict_without_nones(scenario_key))}\\n\" for scenario_key in scenario_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe522fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
