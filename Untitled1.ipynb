{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ca4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from typing import List, Tuple, Set, Any, Optional\n",
    "from nltk import ngrams\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from light_scenario import LightInstance, LightScenario, LightScenarioKey\n",
    "from light_tokenizer import LightTokenizer, DefaultTokenizer\n",
    "from load_documents import get_document_iterator\n",
    "from data_overlap_stats import (\n",
    "    DataOverlapStats,\n",
    "    DataOverlapStatsKey,\n",
    "    PART_INPUT,\n",
    "    PART_REF,\n",
    ")\n",
    "from common.hierarchical_logger import hlog, htrack_block\n",
    "from common.general import asdict_without_nones, write\n",
    "from scenarios.scenario import ScenarioSpec\n",
    "\n",
    "\n",
    "# The n values of the ngrams to be computed\n",
    "N_VALUES: List[int] = [5, 9, 13]  # TODO: Pick the N values\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EntryDataOverlapKey:\n",
    "    \"\"\"Unique key representing either the input or references of a single instance in a scenario.\"\"\"\n",
    "\n",
    "    stats_key: DataOverlapStatsKey\n",
    "    part: str\n",
    "    \"\"\"Either PART_INPUT or PART_REF\"\"\"\n",
    "    instance_id: int\n",
    "\n",
    "\n",
    "# type alias for overlap-related data structures\n",
    "Ngram = Tuple[str, ...]\n",
    "NgramIndex = Dict[int, Dict[Ngram, Set[EntryDataOverlapKey]]]\n",
    "AllDataOverlapStats = Dict[DataOverlapStatsKey, DataOverlapStats]\n",
    "NgramCounter = Dict[EntryDataOverlapKey, Dict[Ngram, int]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973ae115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_light_scenarios_from_jsonl(path: str) -> List[LightScenario]:\n",
    "    \"\"\"\n",
    "    Create a list of light scenarios from a jsonl file, where each json represents a LightScenario object.\n",
    "\n",
    "    Input file format:\n",
    "\n",
    "    Instance JSON 1\n",
    "    Instance JSON 2\n",
    "    Instance JSON 3\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "    def create_light_instance_from_dict(instance_dict: dict) -> LightInstance:\n",
    "        return LightInstance(input=instance_dict[\"input\"], references=instance_dict[\"references\"], id=instance_dict[\"id\"])\n",
    "\n",
    "    light_scenarios: List[LightScenario] = []\n",
    "    light_scenario_jsons = open(path, \"r\").readlines()\n",
    "    for light_scenario_json in light_scenario_jsons:\n",
    "        light_scenario_dict: dict = json.loads(light_scenario_json)\n",
    "\n",
    "        light_scenario_key_dict: dict = light_scenario_dict[\"scenario_key\"]\n",
    "        # if the light_scenarios are exported from helm, they will have a scenario_spec field\n",
    "        scenario_spec = ScenarioSpec(**light_scenario_key_dict[\"scenario_spec\"])\n",
    "        light_scenario_key = LightScenarioKey(scenario_spec=scenario_spec, split=light_scenario_key_dict[\"split\"])\n",
    "        light_instances: List[LightInstance] = [\n",
    "            create_light_instance_from_dict(instance_dict) for instance_dict in light_scenario_dict[\"instances\"]\n",
    "        ]\n",
    "        light_scenarios.append(LightScenario(scenario_key=light_scenario_key, instances=light_instances))\n",
    "    return light_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70ddb43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LightScenarioKey.__init__() got an unexpected keyword argument 'scenario_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m light_scenarios \u001b[38;5;241m=\u001b[39m \u001b[43mload_light_scenarios_from_jsonl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_specs_small\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m, in \u001b[0;36mload_light_scenarios_from_jsonl\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# if the light_scenarios are exported from helm, they will have a scenario_spec field\u001b[39;00m\n\u001b[1;32m     23\u001b[0m scenario_spec \u001b[38;5;241m=\u001b[39m ScenarioSpec(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlight_scenario_key_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscenario_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 24\u001b[0m light_scenario_key \u001b[38;5;241m=\u001b[39m \u001b[43mLightScenarioKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscenario_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlight_scenario_key_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m light_instances: List[LightInstance] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     create_light_instance_from_dict(instance_dict) \u001b[38;5;28;01mfor\u001b[39;00m instance_dict \u001b[38;5;129;01min\u001b[39;00m light_scenario_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m light_scenarios\u001b[38;5;241m.\u001b[39mappend(LightScenario(scenario_key\u001b[38;5;241m=\u001b[39mlight_scenario_key, instances\u001b[38;5;241m=\u001b[39mlight_instances))\n",
      "\u001b[0;31mTypeError\u001b[0m: LightScenarioKey.__init__() got an unexpected keyword argument 'scenario_spec'"
     ]
    }
   ],
   "source": [
    "light_scenarios = load_light_scenarios_from_jsonl('run_specs_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_scenarios[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_all_data_overlap_stats(light_scenarios: List[LightScenario], n_values: List[int]) -> AllDataOverlapStats:\n",
    "    \"\"\"Given a list of scenarios and n values, initialize all_overlap_stats\"\"\"\n",
    "    hlog(\"Initializing all data overlap stats\")\n",
    "    all_overlap_stats: AllDataOverlapStats = {}\n",
    "    for scenario in light_scenarios:\n",
    "        for n in n_values:\n",
    "            # Initialize a stats instance for every pair of <scenario, n>\n",
    "            stats: DataOverlapStats = DataOverlapStats.from_scenario(scenario, stats_tags={\"N\": n})\n",
    "            if stats.stats_key in all_overlap_stats:\n",
    "                raise ValueError(\"Duplicated settings detected.\")\n",
    "            all_overlap_stats[stats.stats_key] = stats\n",
    "    return all_overlap_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392bfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_overlap_stats = create_all_data_overlap_stats(light_scenarios=light_scenarios, n_values=N_VALUES) = create_all_data_overlap_stats(light_scenarios=light_scenarios, n_values=N_VALUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd19bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_overlap_stats)\n",
    "for key in all_overlap_stats.keys():\n",
    "    print(key)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78cd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_index(\n",
    "    light_scenarios: List[LightScenario], n_values: List[int], tokenizer: LightTokenizer\n",
    ") -> NgramIndex:\n",
    "    \"\"\"Given a list of scenarios and n values, initialize ngram_index\"\"\"\n",
    "    ngram_index: NgramIndex = {n: {} for n in n_values}\n",
    "    for scenario in light_scenarios:\n",
    "        hlog(f\"Building ngram indexes for {scenario.scenario_key}\")\n",
    "        for n in n_values:\n",
    "            stats_key = DataOverlapStatsKey(metadata={\"light_scenario_key\": scenario.scenario_key, \"N\": n})\n",
    "            for i in range(len(scenario.instances)):\n",
    "                instance = scenario.instances[i]\n",
    "                input_tokens = tokenizer.tokenize(instance.input)\n",
    "                for input_ngram in ngrams(input_tokens, n):\n",
    "                    if input_ngram not in ngram_index[n]:\n",
    "                        ngram_index[n][input_ngram] = set()\n",
    "                    ngram_index[n][input_ngram].add(\n",
    "                        EntryDataOverlapKey(stats_key=stats_key, instance_id=i, part=PART_INPUT)\n",
    "                    )\n",
    "\n",
    "                # compute reference ngrams\n",
    "                for reference in instance.references:\n",
    "                    reference_unigrams = tokenizer.tokenize(reference)\n",
    "                    for reference_ngram in ngrams(reference_unigrams, n):\n",
    "                        if reference_ngram not in ngram_index[n]:\n",
    "                            ngram_index[n][reference_ngram] = set()\n",
    "                        ngram_index[n][reference_ngram].add(\n",
    "                            EntryDataOverlapKey(stats_key=stats_key, instance_id=i, part=PART_REF)\n",
    "                        )\n",
    "    return ngram_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LightTokenizer()\n",
    "ngram_index = create_ngram_index(light_scenarios=light_scenarios, n_values=N_VALUES, tokenizer=tokenizer)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfe109",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ngram_index)\n",
    "ngram_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ngram_index[5])\n",
    "ngram_index[5].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e86615",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ngram_index[5].items():\n",
    "    if len(v) >= 1:\n",
    "        print(k)\n",
    "        print(v)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd96165",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vv in v:\n",
    "    print(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_key = vv.stats_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_key.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv.part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv.instance_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882f791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
