{"instance": {"input": "The University of Mary Hardin--Baylor (UMHB) is a Christian co-educational institution of higher learning located in Belton, Texas, United States. UMHB was chartered by the Republic of Texas in 1845 as Baylor Female College, the female department of what is now Baylor University. It has since become its own institution and grown to 3,914 students and awards degrees at the baccalaureate, master's, and doctoral levels. It is affiliated with the Baptist General Convention of Texas.\nQuestion: Is baylor and mary hardin baylor the same school?", "references": ["Yes"], "id": "id9450"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9450", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 0], ["university", 0], ["of", 0], ["mary", 0], ["hardin", 0], ["baylor", 0], ["umhb", 0], ["is", 0], ["a", 0], ["christian", 0], ["co", 0], ["educational", 0], ["institution", 0], ["of", 0], ["higher", 0], ["learning", 0], ["located", 0], ["in", 0], ["belton", 0], ["texas", 0], ["united", 0], ["states", 0], ["umhb", 0], ["was", 1], ["chartered", 1], ["by", 1], ["the", 1], ["republic", 1], ["of", 1], ["texas", 1], ["in", 1], ["1845", 1], ["as", 1], ["baylor", 0], ["female", 0], ["college", 0], ["the", 0], ["female", 0], ["department", 0], ["of", 0], ["what", 0], ["is", 0], ["now", 0], ["baylor", 0], ["university", 0], ["it", 0], ["has", 0], ["since", 0], ["become", 0], ["its", 0], ["own", 0], ["institution", 0], ["and", 0], ["grown", 0], ["to", 0], ["3", 0], ["914", 0], ["students", 0], ["and", 0], ["awards", 0], ["degrees", 0], ["at", 0], ["the", 0], ["baccalaureate", 0], ["master", 0], ["s", 0], ["and", 0], ["doctoral", 0], ["levels", 0], ["it", 0], ["is", 0], ["affiliated", 0], ["with", 0], ["the", 0], ["baptist", 0], ["general", 0], ["convention", 0], ["of", 0], ["texas", 0], ["question", 0], ["is", 0], ["baylor", 0], ["and", 0], ["mary", 0], ["hardin", 0], ["baylor", 0], ["the", 0], ["same", 0], ["school", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1282051282051282, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1282051282051282, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.24444444444444444, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.24444444444444444, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.1282051282051282, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.1282051282051282, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.24444444444444444, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.24444444444444444, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Conscription in the United States, commonly known as the draft, has been employed by the federal government of the United States in five conflicts: the American Revolution, the American Civil War, World War I, World War II, and the Cold War (including both the Korean War and the Vietnam War). The third incarnation of the draft came into being in 1940 through the Selective Training and Service Act. It was the country's first peacetime draft. From 1940 until 1973, during both peacetime and periods of conflict, men were drafted to fill vacancies in the United States Armed Forces that could not be filled through voluntary means. The draft came to an end when the United States Armed Forces moved to an all-volunteer military force. However, the Selective Service System remains in place as a contingency plan; all male civilians between the ages of 18 and 25 are required to register so that a draft can be readily resumed if needed. United States Federal Law also provides for the compulsory conscription of men between the ages of 17 and 45 and certain women for militia service pursuant to Article I, Section 8 of the United States Constitution and 10 U.S. Code ยง 246.\nQuestion: Was there a draft in the revolutionary war?", "references": ["Yes"], "id": "id9460"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9460", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["conscription", 1], ["in", 1], ["the", 1], ["united", 1], ["states", 1], ["commonly", 1], ["known", 1], ["as", 1], ["the", 1], ["draft", 1], ["has", 0], ["been", 0], ["employed", 0], ["by", 0], ["the", 0], ["federal", 0], ["government", 0], ["of", 0], ["the", 0], ["united", 0], ["states", 0], ["in", 0], ["five", 0], ["conflicts", 0], ["the", 0], ["american", 0], ["revolution", 0], ["the", 2], ["american", 2], ["civil", 1], ["war", 1], ["world", 1], ["war", 1], ["i", 0], ["world", 0], ["war", 0], ["ii", 0], ["and", 0], ["the", 0], ["cold", 0], ["war", 0], ["including", 0], ["both", 0], ["the", 0], ["korean", 0], ["war", 0], ["and", 0], ["the", 0], ["vietnam", 0], ["war", 0], ["the", 1], ["third", 1], ["incarnation", 1], ["of", 1], ["the", 1], ["draft", 1], ["came", 1], ["into", 1], ["being", 1], ["in", 1], ["1940", 1], ["through", 1], ["the", 1], ["selective", 1], ["training", 1], ["and", 1], ["service", 1], ["act", 1], ["it", 1], ["was", 1], ["the", 1], ["country", 1], ["s", 1], ["first", 1], ["peacetime", 1], ["draft", 1], ["from", 1], ["1940", 1], ["until", 1], ["1973", 1], ["during", 1], ["both", 1], ["peacetime", 1], ["and", 1], ["periods", 1], ["of", 1], ["conflict", 1], ["men", 1], ["were", 1], ["drafted", 1], ["to", 1], ["fill", 1], ["vacancies", 1], ["in", 1], ["the", 1], ["united", 1], ["states", 1], ["armed", 0], ["forces", 0], ["that", 0], ["could", 0], ["not", 0], ["be", 0], ["filled", 0], ["through", 0], ["voluntary", 0], ["means", 0], ["the", 0], ["draft", 0], ["came", 0], ["to", 0], ["an", 0], ["end", 0], ["when", 1], ["the", 1], ["united", 1], ["states", 1], ["armed", 1], ["forces", 1], ["moved", 1], ["to", 1], ["an", 1], ["all", 1], ["volunteer", 1], ["military", 1], ["force", 1], ["however", 1], ["the", 1], ["selective", 1], ["service", 1], ["system", 1], ["remains", 1], ["in", 1], ["place", 1], ["as", 1], ["a", 1], ["contingency", 1], ["plan", 1], ["all", 1], ["male", 1], ["civilians", 1], ["between", 1], ["the", 1], ["ages", 1], ["of", 1], ["18", 1], ["and", 1], ["25", 1], ["are", 1], ["required", 1], ["to", 0], ["register", 0], ["so", 0], ["that", 0], ["a", 0], ["draft", 0], ["can", 0], ["be", 0], ["readily", 0], ["resumed", 0], ["if", 0], ["needed", 0], ["united", 0], ["states", 0], ["federal", 0], ["law", 0], ["also", 0], ["provides", 0], ["for", 0], ["the", 0], ["compulsory", 0], ["conscription", 0], ["of", 0], ["men", 0], ["between", 0], ["the", 0], ["ages", 0], ["of", 0], ["17", 0], ["and", 0], ["45", 0], ["and", 0], ["certain", 0], ["women", 0], ["for", 0], ["militia", 0], ["service", 0], ["pursuant", 0], ["to", 0], ["article", 0], ["i", 0], ["section", 0], ["8", 0], ["of", 0], ["the", 0], ["united", 0], ["states", 0], ["constitution", 0], ["and", 0], ["10", 0], ["u", 0], ["s", 0], ["code", 0], ["ยง", 0], ["246", 0], ["question", 0], ["was", 0], ["there", 0], ["a", 0], ["draft", 0], ["in", 0], ["the", 0], ["revolutionary", 0], ["war", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.49261083743842365, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.4876847290640394, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.6883720930232559, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.6837209302325581, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.49261083743842365, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.4876847290640394, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.6883720930232559, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.6837209302325581, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The White House is the official residence and workplace of the President of the United States. It is located at 1600 Pennsylvania Avenue NW in Washington, D.C. and has been the residence of every U.S. President since John Adams in 1800. The term is often used as a metonym for the president and his advisers.\nQuestion: Does the president live in the white house?", "references": ["Yes"], "id": "id9457"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9457", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 8], ["white", 8], ["house", 7], ["is", 7], ["the", 4], ["official", 4], ["residence", 4], ["and", 4], ["workplace", 4], ["of", 5], ["the", 5], ["president", 4], ["of", 4], ["the", 4], ["united", 4], ["states", 4], ["it", 4], ["is", 3], ["located", 3], ["at", 3], ["1600", 3], ["pennsylvania", 3], ["avenue", 3], ["nw", 3], ["in", 3], ["washington", 3], ["d", 3], ["c", 3], ["and", 4], ["has", 22], ["been", 21], ["the", 17], ["residence", 15], ["of", 0], ["every", 0], ["u", 0], ["s", 0], ["president", 0], ["since", 0], ["john", 0], ["adams", 0], ["in", 0], ["1800", 0], ["the", 0], ["term", 0], ["is", 0], ["often", 0], ["used", 0], ["as", 0], ["a", 0], ["metonym", 0], ["for", 0], ["the", 0], ["president", 0], ["and", 0], ["his", 0], ["advisers", 0], ["question", 0], ["does", 0], ["the", 0], ["president", 0], ["live", 0], ["in", 0], ["the", 0], ["white", 0], ["house", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.6, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1421989953005995, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.6716417910447762, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.19580668088130782, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5272727272727272, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.13822510822510817, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.6716417910447762, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.19580668088130782, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "A new engine is broken in by following specific driving guidelines during the first few hours of its use. The focus of breaking in an engine is on the contact between the piston rings of the engine and the cylinder wall. There is no universal preparation or set of instructions for breaking in an engine. Most importantly, experts disagree on whether it is better to start engines on high or low power to break them in. While there are still consequences to an unsuccessful break-in, they are harder to quantify on modern engines than on older models. In general, people no longer break in the engines of their own vehicles after purchasing a car or motorcycle, because the process is done in production. It is still common, even today, to find that an owner's manual recommends gentle use at first (often specified as the first 500 or 1000 kilometres or miles). But it is usually only normal use without excessive demands that is specified, as opposed to light/limited use. For example, the manual will specify that the car be driven normally, but not in excess of the highway speed limit.\nQuestion: Do you need to break in a car?", "references": ["No"], "id": "id9434"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9434", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["a", 1], ["new", 1], ["engine", 1], ["is", 1], ["broken", 1], ["in", 1], ["by", 1], ["following", 1], ["specific", 1], ["driving", 1], ["guidelines", 1], ["during", 1], ["the", 1], ["first", 1], ["few", 1], ["hours", 1], ["of", 1], ["its", 1], ["use", 1], ["the", 1], ["focus", 1], ["of", 1], ["breaking", 1], ["in", 1], ["an", 1], ["engine", 1], ["is", 1], ["on", 1], ["the", 1], ["contact", 1], ["between", 1], ["the", 1], ["piston", 1], ["rings", 1], ["of", 1], ["the", 1], ["engine", 1], ["and", 1], ["the", 1], ["cylinder", 1], ["wall", 1], ["there", 1], ["is", 1], ["no", 1], ["universal", 1], ["preparation", 1], ["or", 1], ["set", 1], ["of", 1], ["instructions", 1], ["for", 1], ["breaking", 1], ["in", 1], ["an", 1], ["engine", 1], ["most", 1], ["importantly", 1], ["experts", 1], ["disagree", 1], ["on", 1], ["whether", 1], ["it", 1], ["is", 1], ["better", 1], ["to", 1], ["start", 1], ["engines", 1], ["on", 1], ["high", 1], ["or", 1], ["low", 1], ["power", 1], ["to", 1], ["break", 1], ["them", 1], ["in", 1], ["while", 1], ["there", 1], ["are", 1], ["still", 1], ["consequences", 1], ["to", 1], ["an", 1], ["unsuccessful", 1], ["break", 1], ["in", 1], ["they", 1], ["are", 1], ["harder", 1], ["to", 1], ["quantify", 1], ["on", 1], ["modern", 1], ["engines", 1], ["than", 1], ["on", 1], ["older", 1], ["models", 1], ["in", 1], ["general", 1], ["people", 1], ["no", 1], ["longer", 1], ["break", 1], ["in", 1], ["the", 1], ["engines", 1], ["of", 1], ["their", 1], ["own", 1], ["vehicles", 1], ["after", 1], ["purchasing", 1], ["a", 1], ["car", 1], ["or", 1], ["motorcycle", 1], ["because", 1], ["the", 1], ["process", 1], ["is", 1], ["done", 1], ["in", 1], ["production", 1], ["it", 1], ["is", 1], ["still", 1], ["common", 1], ["even", 1], ["today", 1], ["to", 1], ["find", 1], ["that", 1], ["an", 1], ["owner", 1], ["s", 1], ["manual", 1], ["recommends", 1], ["gentle", 0], ["use", 0], ["at", 0], ["first", 0], ["often", 0], ["specified", 0], ["as", 0], ["the", 0], ["first", 0], ["500", 0], ["or", 0], ["1000", 0], ["kilometres", 0], ["or", 1], ["miles", 1], ["but", 1], ["it", 1], ["is", 1], ["usually", 1], ["only", 1], ["normal", 1], ["use", 1], ["without", 1], ["excessive", 1], ["demands", 1], ["that", 1], ["is", 1], ["specified", 1], ["as", 1], ["opposed", 1], ["to", 1], ["light", 1], ["limited", 1], ["use", 1], ["for", 1], ["example", 1], ["the", 1], ["manual", 1], ["will", 1], ["specify", 1], ["that", 1], ["the", 1], ["car", 1], ["be", 0], ["driven", 0], ["normally", 0], ["but", 0], ["not", 0], ["in", 0], ["excess", 0], ["of", 0], ["the", 0], ["highway", 0], ["speed", 0], ["limit", 0], ["question", 0], ["do", 0], ["you", 0], ["need", 0], ["to", 0], ["break", 0], ["in", 0], ["a", 0], ["car", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.8795811518324608, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.8795811518324608, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.9458128078817734, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.9458128078817734, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.8795811518324608, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.8795811518324608, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.9458128078817734, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.9458128078817734, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "The Strangers is a 2008 American slasher film written and directed by Bryan Bertino. Kristen (Liv Tyler) and James (Scott Speedman) are expecting a relaxing weekend at a family vacation home, but their stay turns out to be anything but peaceful as three masked torturers leave Kristen and James struggling for survival. Writer-director Bertino was inspired by real-life events: the Manson family Tate murders, a multiple homicide; the Keddie Cabin Murders, that occurred in California in 1981; and a series of break-ins that occurred in his own neighborhood as a child. Made on a budget of $9 million, the film was shot on location in rural South Carolina in the fall of 2006.\nQuestion: Was the movie strangers based on a true story?", "references": ["Yes"], "id": "id9430"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9430", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 0], ["strangers", 0], ["is", 0], ["a", 0], ["2008", 0], ["american", 0], ["slasher", 0], ["film", 0], ["written", 0], ["and", 0], ["directed", 0], ["by", 0], ["bryan", 0], ["bertino", 0], ["kristen", 1], ["liv", 1], ["tyler", 1], ["and", 1], ["james", 1], ["scott", 1], ["speedman", 1], ["are", 1], ["expecting", 1], ["a", 1], ["relaxing", 1], ["weekend", 1], ["at", 1], ["a", 1], ["family", 1], ["vacation", 0], ["home", 0], ["but", 0], ["their", 0], ["stay", 0], ["turns", 0], ["out", 0], ["to", 0], ["be", 0], ["anything", 0], ["but", 0], ["peaceful", 0], ["as", 0], ["three", 0], ["masked", 0], ["torturers", 0], ["leave", 0], ["kristen", 0], ["and", 0], ["james", 0], ["struggling", 0], ["for", 0], ["survival", 0], ["writer", 0], ["director", 0], ["bertino", 0], ["was", 0], ["inspired", 0], ["by", 0], ["real", 0], ["life", 0], ["events", 0], ["the", 0], ["manson", 0], ["family", 0], ["tate", 0], ["murders", 0], ["a", 0], ["multiple", 0], ["homicide", 0], ["the", 0], ["keddie", 0], ["cabin", 0], ["murders", 0], ["that", 0], ["occurred", 0], ["in", 0], ["california", 0], ["in", 0], ["1981", 0], ["and", 0], ["a", 0], ["series", 0], ["of", 0], ["break", 0], ["ins", 0], ["that", 0], ["occurred", 0], ["in", 0], ["his", 0], ["own", 0], ["neighborhood", 0], ["as", 0], ["a", 0], ["child", 0], ["made", 0], ["on", 0], ["a", 0], ["budget", 0], ["of", 0], ["9", 0], ["million", 0], ["the", 0], ["film", 0], ["was", 0], ["shot", 0], ["on", 0], ["location", 0], ["in", 0], ["rural", 0], ["south", 0], ["carolina", 0], ["in", 0], ["the", 0], ["fall", 0], ["of", 0], ["2006", 0], ["question", 0], ["was", 0], ["the", 0], ["movie", 0], ["strangers", 0], ["based", 0], ["on", 0], ["a", 0], ["true", 0], ["story", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.13043478260869565, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.13043478260869565, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.2125984251968504, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.2125984251968504, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.13043478260869565, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.13043478260869565, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.2125984251968504, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.2125984251968504, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The Fate of the Furious premiered in Berlin on April 4, 2017, and was theatrically released in the United States on April 14, 2017, playing in 3D, IMAX 3D and 4DX internationally. The film received mixed reviews from critics, many of whom praised the action sequences and acting performances but criticized the storyline. The film grossed over $1.2 billion worldwide, making it the thirtieth film (and the second in the franchise, after Furious 7) to gross over $1 billion, the third-highest-grossing film of 2017 and the fifteenth-highest-grossing film of all time. The film grossed $542 million worldwide during its opening weekend, which is the second highest-grossing worldwide opening of all time behind Avengers: Infinity War (2018). A spinoff film starring Johnson and Statham's characters is scheduled for release in August 2019, while the ninth and tenth films are scheduled for releases on the years 2020 and 2021.\nQuestion: Is fate and the furious the last movie?", "references": ["No"], "id": "id9471"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9471", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 0], ["fate", 0], ["of", 0], ["the", 0], ["furious", 0], ["premiered", 0], ["in", 0], ["berlin", 0], ["on", 0], ["april", 0], ["4", 0], ["2017", 0], ["and", 1], ["was", 1], ["theatrically", 1], ["released", 1], ["in", 1], ["the", 1], ["united", 1], ["states", 1], ["on", 1], ["april", 0], ["14", 0], ["2017", 0], ["playing", 0], ["in", 0], ["3d", 0], ["imax", 0], ["3d", 0], ["and", 0], ["4dx", 0], ["internationally", 0], ["the", 0], ["film", 0], ["received", 0], ["mixed", 0], ["reviews", 0], ["from", 0], ["critics", 0], ["many", 0], ["of", 0], ["whom", 0], ["praised", 0], ["the", 0], ["action", 0], ["sequences", 0], ["and", 0], ["acting", 0], ["performances", 0], ["but", 0], ["criticized", 0], ["the", 0], ["storyline", 0], ["the", 0], ["film", 0], ["grossed", 0], ["over", 0], ["1", 0], ["2", 0], ["billion", 0], ["worldwide", 0], ["making", 0], ["it", 0], ["the", 0], ["thirtieth", 0], ["film", 0], ["and", 0], ["the", 0], ["second", 0], ["in", 0], ["the", 0], ["franchise", 0], ["after", 0], ["furious", 0], ["7", 0], ["to", 0], ["gross", 0], ["over", 0], ["1", 0], ["billion", 0], ["the", 0], ["third", 0], ["highest", 0], ["grossing", 0], ["film", 0], ["of", 0], ["2017", 0], ["and", 0], ["the", 0], ["fifteenth", 0], ["highest", 0], ["grossing", 0], ["film", 0], ["of", 0], ["all", 0], ["time", 0], ["the", 0], ["film", 0], ["grossed", 0], ["542", 0], ["million", 0], ["worldwide", 0], ["during", 0], ["its", 0], ["opening", 0], ["weekend", 0], ["which", 0], ["is", 0], ["the", 0], ["second", 0], ["highest", 0], ["grossing", 0], ["worldwide", 0], ["opening", 0], ["of", 0], ["all", 0], ["time", 0], ["behind", 0], ["avengers", 0], ["infinity", 0], ["war", 0], ["2018", 0], ["a", 0], ["spinoff", 0], ["film", 0], ["starring", 0], ["johnson", 0], ["and", 0], ["statham", 0], ["s", 0], ["characters", 0], ["is", 0], ["scheduled", 0], ["for", 0], ["release", 0], ["in", 0], ["august", 0], ["2019", 0], ["while", 0], ["the", 0], ["ninth", 0], ["and", 0], ["tenth", 0], ["films", 0], ["are", 0], ["scheduled", 0], ["for", 0], ["releases", 0], ["on", 0], ["the", 0], ["years", 0], ["2020", 0], ["and", 0], ["2021", 0], ["question", 0], ["is", 0], ["fate", 0], ["and", 0], ["the", 0], ["furious", 0], ["the", 0], ["last", 0], ["movie", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.05921052631578947, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.05921052631578947, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.12804878048780488, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.12804878048780488, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.05921052631578947, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.05921052631578947, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.12804878048780488, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.12804878048780488, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "``Chasing Cars'' is a song by Northern Irish alternative rock band Snow Patrol. It was released as the second single from their fourth studio album, Eyes Open (2006). It was recorded in 2005 and released on 6 June 2006 in the United States and 24 July 2006 in the United Kingdom. The song gained significant popularity in the US after being featured in the second season finale of the popular medical drama Grey's Anatomy, which aired on 15 May 2006.\nQuestion: Was chasing cars written for grey's anatomy?", "references": ["No"], "id": "id9458"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9458", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["", 0], ["chasing", 0], ["cars", 0], ["is", 0], ["a", 0], ["song", 0], ["by", 0], ["northern", 0], ["irish", 0], ["alternative", 0], ["rock", 0], ["band", 0], ["snow", 0], ["patrol", 0], ["it", 0], ["was", 0], ["released", 0], ["as", 0], ["the", 0], ["second", 0], ["single", 0], ["from", 0], ["their", 0], ["fourth", 0], ["studio", 0], ["album", 0], ["eyes", 0], ["open", 0], ["2006", 0], ["it", 0], ["was", 0], ["recorded", 0], ["in", 0], ["2005", 0], ["and", 0], ["released", 0], ["on", 0], ["6", 0], ["june", 0], ["2006", 0], ["in", 0], ["the", 0], ["united", 0], ["states", 0], ["and", 0], ["24", 0], ["july", 0], ["2006", 0], ["in", 0], ["the", 0], ["united", 0], ["kingdom", 0], ["the", 0], ["song", 0], ["gained", 0], ["significant", 0], ["popularity", 0], ["in", 1], ["the", 0], ["us", 0], ["after", 0], ["being", 0], ["featured", 0], ["in", 0], ["the", 0], ["second", 0], ["season", 0], ["finale", 0], ["of", 0], ["the", 0], ["popular", 0], ["medical", 0], ["drama", 0], ["grey", 0], ["s", 0], ["anatomy", 0], ["which", 0], ["aired", 0], ["on", 0], ["15", 0], ["may", 0], ["2006", 0], ["question", 0], ["was", 0], ["chasing", 0], ["cars", 0], ["written", 0], ["for", 0], ["grey", 0], ["s", 0], ["anatomy", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.0125, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.0125, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.14130434782608695, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.14130434782608695, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.0125, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.0125, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.14130434782608695, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.14130434782608695, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "A floating island is a mass of floating aquatic plants, mud, and peat ranging in thickness from several centimetres to a few metres. Floating islands are a common natural phenomenon that are found in many parts of the world. They exist less commonly as a man-made phenomenon. Floating islands are generally found on marshlands, lakes, and similar wetland locations, and can be many hectares in size.\nQuestion: Is there such a thing as a floating island?", "references": ["Yes"], "id": "id9452"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9452", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["a", 0], ["floating", 0], ["island", 0], ["is", 0], ["a", 1], ["mass", 0], ["of", 0], ["floating", 0], ["aquatic", 0], ["plants", 0], ["mud", 0], ["and", 0], ["peat", 0], ["ranging", 0], ["in", 0], ["thickness", 0], ["from", 0], ["several", 0], ["centimetres", 0], ["to", 0], ["a", 0], ["few", 0], ["metres", 0], ["floating", 0], ["islands", 0], ["are", 0], ["a", 0], ["common", 0], ["natural", 0], ["phenomenon", 0], ["that", 0], ["are", 0], ["found", 0], ["in", 0], ["many", 0], ["parts", 0], ["of", 0], ["the", 0], ["world", 0], ["they", 0], ["exist", 0], ["less", 0], ["commonly", 0], ["as", 0], ["a", 0], ["man", 0], ["made", 0], ["phenomenon", 0], ["floating", 0], ["islands", 0], ["are", 0], ["generally", 0], ["found", 0], ["on", 0], ["marshlands", 0], ["lakes", 0], ["and", 0], ["similar", 0], ["wetland", 0], ["locations", 0], ["and", 0], ["can", 0], ["be", 0], ["many", 0], ["hectares", 0], ["in", 0], ["size", 0], ["question", 0], ["is", 0], ["there", 0], ["such", 0], ["a", 0], ["thing", 0], ["as", 0], ["a", 0], ["floating", 0], ["island", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.015151515151515152, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.015151515151515152, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.16666666666666666, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.16666666666666666, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.015151515151515152, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.015151515151515152, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.16666666666666666, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.16666666666666666, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Indiana Jones and the Temple of Doom is a 1984 American action-adventure film directed by Steven Spielberg. It is the second installment in the Indiana Jones franchise and a prequel to the 1981 film Raiders of the Lost Ark, featuring Harrison Ford reprising his role as the title character. After arriving in North India, Indiana Jones is asked by desperate villagers to find a mystical stone and rescue their children from a Thuggee cult practicing child slavery, black magic and ritual human sacrifice in honor of the goddess Kali.\nQuestion: Is indiana jones temple of doom a prequel?", "references": ["Yes"], "id": "id9437"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9437", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["indiana", 1], ["jones", 1], ["and", 1], ["the", 1], ["temple", 0], ["of", 0], ["doom", 0], ["is", 0], ["a", 0], ["1984", 0], ["american", 0], ["action", 0], ["adventure", 1], ["film", 1], ["directed", 1], ["by", 1], ["steven", 1], ["spielberg", 1], ["it", 1], ["is", 1], ["the", 1], ["second", 1], ["installment", 1], ["in", 0], ["the", 0], ["indiana", 0], ["jones", 0], ["franchise", 0], ["and", 0], ["a", 0], ["prequel", 0], ["to", 0], ["the", 0], ["1981", 0], ["film", 0], ["raiders", 0], ["of", 0], ["the", 0], ["lost", 0], ["ark", 0], ["featuring", 0], ["harrison", 0], ["ford", 0], ["reprising", 0], ["his", 0], ["role", 0], ["as", 0], ["the", 0], ["title", 0], ["character", 0], ["after", 0], ["arriving", 0], ["in", 0], ["north", 0], ["india", 0], ["indiana", 0], ["jones", 0], ["is", 0], ["asked", 0], ["by", 0], ["desperate", 0], ["villagers", 0], ["to", 0], ["find", 0], ["a", 0], ["mystical", 0], ["stone", 0], ["and", 0], ["rescue", 0], ["their", 0], ["children", 0], ["from", 0], ["a", 0], ["thuggee", 0], ["cult", 0], ["practicing", 0], ["child", 0], ["slavery", 0], ["black", 0], ["magic", 0], ["and", 0], ["ritual", 0], ["human", 0], ["sacrifice", 0], ["in", 0], ["honor", 0], ["of", 0], ["the", 0], ["goddess", 0], ["kali", 0], ["question", 0], ["is", 0], ["indiana", 0], ["jones", 0], ["temple", 0], ["of", 0], ["doom", 0], ["a", 0], ["prequel", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.17045454545454544, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.17045454545454544, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.35, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.35, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.17045454545454544, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.17045454545454544, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.35, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.35, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Anosmia is the inability to perceive odor or a lack of functioning olfaction--the loss of the sense of smell. Anosmia may be temporary, but some forms such as from an accident, can be permanent. Anosmia is due to a number of factors, including an inflammation of the nasal mucosa, blockage of nasal passages or a destruction of one temporal lobe. Inflammation is due to chronic mucosa changes in the paranasal sinus lining and the middle and superior turbinates.\nQuestion: Is it possible to have no sense of smell?", "references": ["Yes"], "id": "id9473"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9473", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["anosmia", 0], ["is", 0], ["the", 0], ["inability", 0], ["to", 0], ["perceive", 0], ["odor", 0], ["or", 0], ["a", 0], ["lack", 0], ["of", 0], ["functioning", 0], ["olfaction", 0], ["the", 0], ["loss", 0], ["of", 0], ["the", 0], ["sense", 0], ["of", 0], ["smell", 0], ["anosmia", 0], ["may", 0], ["be", 0], ["temporary", 0], ["but", 0], ["some", 0], ["forms", 0], ["such", 0], ["as", 0], ["from", 0], ["an", 0], ["accident", 0], ["can", 0], ["be", 0], ["permanent", 0], ["anosmia", 0], ["is", 0], ["due", 0], ["to", 0], ["a", 0], ["number", 0], ["of", 0], ["factors", 0], ["including", 0], ["an", 2], ["inflammation", 2], ["of", 2], ["the", 2], ["nasal", 2], ["mucosa", 1], ["blockage", 1], ["of", 1], ["nasal", 1], ["passages", 1], ["or", 0], ["a", 0], ["destruction", 0], ["of", 0], ["one", 0], ["temporal", 0], ["lobe", 0], ["inflammation", 0], ["is", 0], ["due", 0], ["to", 0], ["chronic", 0], ["mucosa", 0], ["changes", 0], ["in", 0], ["the", 0], ["paranasal", 0], ["sinus", 0], ["lining", 0], ["and", 0], ["the", 0], ["middle", 0], ["and", 0], ["superior", 0], ["turbinates", 0], ["question", 0], ["is", 0], ["it", 0], ["possible", 0], ["to", 0], ["have", 0], ["no", 0], ["sense", 0], ["of", 0], ["smell", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1282051282051282, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.09615384615384616, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.24444444444444444, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.21666666666666667, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.1282051282051282, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.09615384615384616, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.24444444444444444, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.21666666666666667, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Because the courts of appeals possess only appellate jurisdiction, they do not hold trials. Only courts with original jurisdiction hold trials and thus determine punishments (in criminal cases) and remedies (in civil cases). Instead, appeals courts review decisions of trial courts for errors of law. Accordingly, an appeals court considers only the record (that is, the papers the parties filed and the transcripts and any exhibits from any trial) from the trial court, and the legal arguments of the parties. These arguments, which are presented in written form and can range in length from dozens to hundreds of pages, are known as briefs. Sometimes lawyers are permitted to add to their written briefs with oral arguments before the appeals judges. At such hearings, only the parties' lawyers speak to the court.\nQuestion: Does the us court of appeals have original jurisdiction?", "references": ["No"], "id": "id9488"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9488", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["because", 1], ["the", 1], ["courts", 0], ["of", 0], ["appeals", 0], ["possess", 0], ["only", 0], ["appellate", 0], ["jurisdiction", 0], ["they", 0], ["do", 0], ["not", 0], ["hold", 0], ["trials", 0], ["only", 0], ["courts", 0], ["with", 0], ["original", 0], ["jurisdiction", 0], ["hold", 0], ["trials", 0], ["and", 0], ["thus", 0], ["determine", 0], ["punishments", 0], ["in", 0], ["criminal", 0], ["cases", 0], ["and", 0], ["remedies", 0], ["in", 0], ["civil", 0], ["cases", 0], ["instead", 1], ["appeals", 0], ["courts", 0], ["review", 0], ["decisions", 0], ["of", 0], ["trial", 0], ["courts", 0], ["for", 0], ["errors", 0], ["of", 0], ["law", 0], ["accordingly", 0], ["an", 0], ["appeals", 0], ["court", 0], ["considers", 0], ["only", 0], ["the", 0], ["record", 0], ["that", 0], ["is", 0], ["the", 0], ["papers", 0], ["the", 0], ["parties", 0], ["filed", 0], ["and", 0], ["the", 0], ["transcripts", 0], ["and", 0], ["any", 0], ["exhibits", 0], ["from", 0], ["any", 0], ["trial", 0], ["from", 0], ["the", 0], ["trial", 0], ["court", 0], ["and", 0], ["the", 0], ["legal", 0], ["arguments", 0], ["of", 0], ["the", 0], ["parties", 0], ["these", 0], ["arguments", 0], ["which", 0], ["are", 0], ["presented", 0], ["in", 0], ["written", 0], ["form", 1], ["and", 1], ["can", 1], ["range", 1], ["in", 1], ["length", 1], ["from", 1], ["dozens", 1], ["to", 1], ["hundreds", 1], ["of", 1], ["pages", 1], ["are", 1], ["known", 1], ["as", 1], ["briefs", 1], ["sometimes", 1], ["lawyers", 1], ["are", 1], ["permitted", 1], ["to", 1], ["add", 1], ["to", 1], ["their", 1], ["written", 1], ["briefs", 1], ["with", 1], ["oral", 1], ["arguments", 1], ["before", 1], ["the", 1], ["appeals", 1], ["judges", 0], ["at", 0], ["such", 0], ["hearings", 0], ["only", 0], ["the", 0], ["parties", 0], ["lawyers", 0], ["speak", 0], ["to", 0], ["the", 0], ["court", 0], ["question", 0], ["does", 0], ["the", 0], ["us", 0], ["court", 0], ["of", 0], ["appeals", 0], ["have", 0], ["original", 0], ["jurisdiction", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.2692307692307692, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.2692307692307692, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.5, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.2692307692307692, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.2692307692307692, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.5, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "The Willis Tower, built as and still commonly referred to as the Sears Tower, is a 110-story, 1,450-foot (442.1 m) skyscraper in Chicago, Illinois. At completion in 1973, it surpassed the World Trade Center towers in New York to become the tallest building in the world, a title it held for nearly 25 years; it remained the tallest building in the Western Hemisphere until the completion of a new building at the World Trade Center site in 2014. The building is considered a seminal achievement for its designer Fazlur Rahman Khan. The Willis Tower is the second-tallest building in the United States and the Western hemisphere -- and the 16th-tallest in the world. More than one million people visit its observation deck each year, making it one of Chicago's most-popular tourist destinations. The structure was renamed in 2009 by the Willis Group as part of its lease on a portion of the tower's space.\nQuestion: Was the sears tower the tallest building in the world?", "references": ["Yes"], "id": "id9472"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9472", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 2], ["willis", 2], ["tower", 2], ["built", 2], ["as", 2], ["and", 2], ["still", 2], ["commonly", 2], ["referred", 2], ["to", 2], ["as", 2], ["the", 2], ["sears", 2], ["tower", 2], ["is", 2], ["a", 2], ["110", 1], ["story", 1], ["1", 1], ["450", 1], ["foot", 1], ["442", 1], ["1", 1], ["m", 1], ["skyscraper", 1], ["in", 1], ["chicago", 0], ["illinois", 0], ["at", 1], ["completion", 1], ["in", 1], ["1973", 1], ["it", 1], ["surpassed", 1], ["the", 1], ["world", 1], ["trade", 1], ["center", 1], ["towers", 1], ["in", 2], ["new", 2], ["york", 2], ["to", 2], ["become", 2], ["the", 3], ["tallest", 3], ["building", 2], ["in", 2], ["the", 2], ["world", 2], ["a", 1], ["title", 1], ["it", 1], ["held", 1], ["for", 1], ["nearly", 1], ["25", 1], ["years", 1], ["it", 1], ["remained", 1], ["the", 1], ["tallest", 1], ["building", 1], ["in", 1], ["the", 0], ["western", 0], ["hemisphere", 0], ["until", 0], ["the", 0], ["completion", 0], ["of", 0], ["a", 0], ["new", 0], ["building", 0], ["at", 0], ["the", 0], ["world", 0], ["trade", 0], ["center", 0], ["site", 0], ["in", 0], ["2014", 0], ["the", 0], ["building", 0], ["is", 0], ["considered", 0], ["a", 0], ["seminal", 0], ["achievement", 0], ["for", 0], ["its", 0], ["designer", 0], ["fazlur", 0], ["rahman", 0], ["khan", 0], ["the", 0], ["willis", 0], ["tower", 0], ["is", 0], ["the", 0], ["second", 0], ["tallest", 0], ["building", 0], ["in", 0], ["the", 0], ["united", 0], ["states", 0], ["and", 0], ["the", 0], ["western", 0], ["hemisphere", 0], ["and", 1], ["the", 1], ["16th", 1], ["tallest", 1], ["in", 1], ["the", 1], ["world", 1], ["more", 3], ["than", 3], ["one", 3], ["million", 1], ["people", 1], ["visit", 1], ["its", 1], ["observation", 1], ["deck", 1], ["each", 1], ["year", 1], ["making", 1], ["it", 1], ["one", 1], ["of", 1], ["chicago", 1], ["s", 1], ["most", 3], ["popular", 3], ["tourist", 3], ["destinations", 2], ["the", 2], ["structure", 2], ["was", 2], ["renamed", 2], ["in", 2], ["2009", 2], ["by", 2], ["the", 2], ["willis", 0], ["group", 0], ["as", 0], ["part", 0], ["of", 0], ["its", 0], ["lease", 0], ["on", 0], ["a", 0], ["portion", 0], ["of", 0], ["the", 0], ["tower", 0], ["s", 0], ["space", 0], ["question", 0], ["was", 0], ["the", 0], ["sears", 0], ["tower", 0], ["the", 0], ["tallest", 0], ["building", 0], ["in", 0], ["the", 0], ["world", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.6049382716049383, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.46707818930041145, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.7126436781609196, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.6666666666666666, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.6049382716049383, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.46707818930041145, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.7126436781609196, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.6666666666666666, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Columbus Day is a national holiday in many countries of the Americas and elsewhere which officially celebrates the anniversary of Christopher Columbus's arrival in the Americas on October 12, 1492. The landing is celebrated as ``Columbus Day'' in the United States, as ``Dรญa de la Raza'' (``Day of the Race'') in some countries in Latin America, as ``Dรญa de la Hispanidad'' and ``Fiesta Nacional'' in Spain, where it is also the religious festivity of la Virgen del Pilar, as Dรญa de las Amรฉricas (Day of the Americas) in Belize and Uruguay, as Dรญa del Respeto a la Diversidad Cultural (Day of Respect for Cultural Diversity) in Argentina, and as Giornata Nazionale di Cristoforo Colombo or Festa Nazionale di Cristoforo Colombo in Italy as well as in Little Italys around the world. As the day of remembrance of Our Lady of the Pillar, 12 October had been declared a religious feast day throughout the Spanish Empire in 1730; the secular Fiesta de la Raza Espaรฑola was first proposed by Faustino Rodrรญguez-San Pedro y Dรญaz-Argรผelles in 1913. In recent years, celebration of the holiday has faced some opposition from various organizations.\nQuestion: Is columbus day a national holiday in the united states?", "references": ["Yes"], "id": "id9439"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9439", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["columbus", 4], ["day", 4], ["is", 3], ["a", 3], ["national", 3], ["holiday", 3], ["in", 3], ["many", 3], ["countries", 3], ["of", 2], ["the", 3], ["americas", 3], ["and", 3], ["elsewhere", 2], ["which", 2], ["officially", 2], ["celebrates", 2], ["the", 2], ["anniversary", 2], ["of", 1], ["christopher", 1], ["columbus", 1], ["s", 1], ["arrival", 2], ["in", 2], ["the", 2], ["americas", 2], ["on", 4], ["october", 4], ["12", 4], ["1492", 1], ["the", 1], ["landing", 1], ["is", 3], ["celebrated", 3], ["as", 3], ["columbus", 3], ["day", 3], ["in", 2], ["the", 2], ["united", 0], ["states", 0], ["as", 0], ["dรญa", 0], ["de", 0], ["la", 0], ["raza", 0], ["day", 0], ["of", 0], ["the", 0], ["race", 0], ["in", 0], ["some", 0], ["countries", 1], ["in", 1], ["latin", 1], ["america", 1], ["as", 1], ["dรญa", 1], ["de", 1], ["la", 1], ["hispanidad", 1], ["and", 1], ["fiesta", 1], ["nacional", 1], ["in", 1], ["spain", 1], ["where", 1], ["it", 1], ["is", 1], ["also", 1], ["the", 1], ["religious", 1], ["festivity", 1], ["of", 1], ["la", 1], ["virgen", 1], ["del", 1], ["pilar", 1], ["as", 1], ["dรญa", 1], ["de", 1], ["las", 1], ["amรฉricas", 1], ["day", 1], ["of", 1], ["the", 1], ["americas", 1], ["in", 1], ["belize", 1], ["and", 1], ["uruguay", 1], ["as", 1], ["dรญa", 1], ["del", 2], ["respeto", 2], ["a", 2], ["la", 2], ["diversidad", 1], ["cultural", 1], ["day", 1], ["of", 1], ["respect", 1], ["for", 1], ["cultural", 1], ["diversity", 1], ["in", 1], ["argentina", 1], ["and", 1], ["as", 1], ["giornata", 1], ["nazionale", 0], ["di", 0], ["cristoforo", 0], ["colombo", 0], ["or", 0], ["festa", 0], ["nazionale", 0], ["di", 0], ["cristoforo", 0], ["colombo", 0], ["in", 0], ["italy", 0], ["as", 0], ["well", 0], ["as", 0], ["in", 0], ["little", 0], ["italys", 0], ["around", 0], ["the", 0], ["world", 0], ["as", 0], ["the", 0], ["day", 0], ["of", 0], ["remembrance", 0], ["of", 0], ["our", 0], ["lady", 0], ["of", 0], ["the", 0], ["pillar", 0], ["12", 0], ["october", 0], ["had", 0], ["been", 0], ["declared", 0], ["a", 0], ["religious", 0], ["feast", 0], ["day", 0], ["throughout", 0], ["the", 0], ["spanish", 0], ["empire", 0], ["in", 0], ["1730", 0], ["the", 0], ["secular", 0], ["fiesta", 0], ["de", 0], ["la", 0], ["raza", 0], ["espaรฑola", 0], ["was", 0], ["first", 0], ["proposed", 0], ["by", 0], ["faustino", 0], ["rodrรญguez", 0], ["san", 0], ["pedro", 0], ["y", 0], ["dรญaz", 0], ["argรผelles", 0], ["in", 0], ["1913", 0], ["in", 0], ["recent", 0], ["years", 0], ["celebration", 0], ["of", 0], ["the", 0], ["holiday", 0], ["has", 0], ["faced", 0], ["some", 0], ["opposition", 0], ["from", 0], ["various", 0], ["organizations", 0], ["question", 0], ["is", 0], ["columbus", 0], ["day", 0], ["a", 0], ["national", 0], ["holiday", 0], ["in", 0], ["the", 0], ["united", 0], ["states", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5104166666666666, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.39453125, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.5980392156862745, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5433006535947713, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5104166666666666, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.39453125, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.5980392156862745, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5433006535947713, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Journey 2: The Mysterious Island is a 2012 American science fiction comedy adventure film directed by Brad Peyton and produced by Beau Flynn, Tripp Vinson and Charlotte Huggins. It is the sequel to Journey to the Center of the Earth (2008). Following the first film, the sequel is based on another Jules Verne novel, this time The Mysterious Island. The film stars Dwayne ``The Rock'' Johnson, Michael Caine, Josh Hutcherson, Vanessa Hudgens, Luis Guzmรกn, and Kristin Davis. The story was written by Richard Outten, Brian Gunn and Mark Gunn, and the screenplay by Brian and Mark Gunn. Journey 2: The Mysterious Island was released in cinemas on February 10, 2012 by Warner Bros. Pictures, New Line Cinema and Walden Media to mixed reviews, but became a box office success with a worldwide gross of nearly $335 million, surpassing its predecessor. Journey 2: The Mysterious Island was released on DVD/Blu-ray on June 5, 2012.\nQuestion: Is journey 2 the mysterious island a sequel?", "references": ["Yes"], "id": "id9464"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9464", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["journey", 1], ["2", 1], ["the", 1], ["mysterious", 1], ["island", 1], ["is", 1], ["a", 1], ["2012", 1], ["american", 1], ["science", 1], ["fiction", 1], ["comedy", 1], ["adventure", 1], ["film", 1], ["directed", 0], ["by", 0], ["brad", 0], ["peyton", 0], ["and", 0], ["produced", 0], ["by", 0], ["beau", 0], ["flynn", 0], ["tripp", 0], ["vinson", 0], ["and", 0], ["charlotte", 0], ["huggins", 0], ["it", 0], ["is", 0], ["the", 0], ["sequel", 0], ["to", 0], ["journey", 0], ["to", 0], ["the", 0], ["center", 0], ["of", 0], ["the", 0], ["earth", 0], ["2008", 0], ["following", 0], ["the", 0], ["first", 0], ["film", 0], ["the", 0], ["sequel", 0], ["is", 0], ["based", 0], ["on", 0], ["another", 0], ["jules", 0], ["verne", 0], ["novel", 0], ["this", 0], ["time", 0], ["the", 0], ["mysterious", 0], ["island", 0], ["the", 0], ["film", 0], ["stars", 0], ["dwayne", 0], ["the", 0], ["rock", 0], ["johnson", 0], ["michael", 0], ["caine", 0], ["josh", 0], ["hutcherson", 0], ["vanessa", 0], ["hudgens", 0], ["luis", 0], ["guzmรกn", 0], ["and", 0], ["kristin", 0], ["davis", 0], ["the", 0], ["story", 0], ["was", 0], ["written", 0], ["by", 0], ["richard", 0], ["outten", 0], ["brian", 0], ["gunn", 0], ["and", 0], ["mark", 0], ["gunn", 0], ["and", 0], ["the", 0], ["screenplay", 0], ["by", 0], ["brian", 0], ["and", 0], ["mark", 0], ["gunn", 0], ["journey", 0], ["2", 0], ["the", 0], ["mysterious", 0], ["island", 0], ["was", 0], ["released", 0], ["in", 0], ["cinemas", 0], ["on", 0], ["february", 0], ["10", 0], ["2012", 0], ["by", 0], ["warner", 0], ["bros", 0], ["pictures", 0], ["new", 0], ["line", 0], ["cinema", 0], ["and", 0], ["walden", 0], ["media", 0], ["to", 0], ["mixed", 0], ["reviews", 0], ["but", 0], ["became", 0], ["a", 0], ["box", 0], ["office", 0], ["success", 0], ["with", 0], ["a", 0], ["worldwide", 0], ["gross", 0], ["of", 0], ["nearly", 0], ["335", 0], ["million", 0], ["surpassing", 0], ["its", 0], ["predecessor", 0], ["journey", 0], ["2", 0], ["the", 0], ["mysterious", 0], ["island", 0], ["was", 0], ["released", 0], ["on", 0], ["dvd", 0], ["blu", 0], ["ray", 0], ["on", 0], ["june", 0], ["5", 0], ["2012", 0], ["question", 0], ["is", 0], ["journey", 0], ["2", 0], ["the", 0], ["mysterious", 0], ["island", 0], ["a", 0], ["sequel", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.0915032679738562, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.0915032679738562, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.15757575757575756, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.15757575757575756, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.0915032679738562, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.0915032679738562, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.15757575757575756, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.15757575757575756, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The Isle of Man holds neither membership nor associate membership of the European Union, and lies outside the European Economic Area (EEA). Nonetheless, Protocol 3 permits trade in Manx goods without non-EU tariffs. In conjunction with the Customs and Excise agreement with the UK, this facilitates free trade with the UK. While Manx goods can be freely moved within the EEA, people, capital and services cannot.\nQuestion: Is the isle of man part of the european economic area?", "references": ["No"], "id": "id9476"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9476", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 1], ["isle", 1], ["of", 0], ["man", 0], ["holds", 0], ["neither", 0], ["membership", 0], ["nor", 0], ["associate", 0], ["membership", 0], ["of", 0], ["the", 0], ["european", 0], ["union", 0], ["and", 0], ["lies", 0], ["outside", 0], ["the", 0], ["european", 0], ["economic", 0], ["area", 0], ["eea", 0], ["nonetheless", 0], ["protocol", 0], ["3", 0], ["permits", 0], ["trade", 0], ["in", 0], ["manx", 0], ["goods", 0], ["without", 0], ["non", 0], ["eu", 0], ["tariffs", 0], ["in", 1], ["conjunction", 1], ["with", 1], ["the", 1], ["customs", 1], ["and", 1], ["excise", 1], ["agreement", 1], ["with", 1], ["the", 1], ["uk", 1], ["this", 1], ["facilitates", 1], ["free", 1], ["trade", 1], ["with", 0], ["the", 0], ["uk", 0], ["while", 0], ["manx", 0], ["goods", 0], ["can", 0], ["be", 0], ["freely", 0], ["moved", 0], ["within", 0], ["the", 0], ["eea", 0], ["people", 0], ["capital", 0], ["and", 0], ["services", 0], ["cannot", 0], ["question", 0], ["is", 0], ["the", 0], ["isle", 0], ["of", 0], ["man", 0], ["part", 0], ["of", 0], ["the", 0], ["european", 0], ["economic", 0], ["area", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.25, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.25, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.5125, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5125, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.25, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.25, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.5125, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5125, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "Phantom pain sensations are described as perceptions that an individual experiences relating to a limb or an organ that is not physically part of the body. Limb loss is a result of either removal by amputation or congenital limb deficiency. However, phantom limb sensations can also occur following nerve avulsion or spinal cord injury.\nQuestion: Is pain experienced in a missing body part or paralyzed area?", "references": ["Yes"], "id": "id9427"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9427", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["phantom", 2], ["pain", 2], ["sensations", 1], ["are", 1], ["described", 1], ["as", 1], ["perceptions", 1], ["that", 1], ["an", 1], ["individual", 1], ["experiences", 1], ["relating", 1], ["to", 1], ["a", 1], ["limb", 1], ["or", 1], ["an", 1], ["organ", 1], ["that", 1], ["is", 1], ["not", 1], ["physically", 1], ["part", 1], ["of", 1], ["the", 1], ["body", 1], ["limb", 1], ["loss", 1], ["is", 0], ["a", 0], ["result", 0], ["of", 0], ["either", 0], ["removal", 0], ["by", 0], ["amputation", 0], ["or", 0], ["congenital", 0], ["limb", 0], ["deficiency", 0], ["however", 1], ["phantom", 1], ["limb", 0], ["sensations", 0], ["can", 0], ["also", 0], ["occur", 0], ["following", 0], ["nerve", 0], ["avulsion", 0], ["or", 0], ["spinal", 0], ["cord", 0], ["injury", 0], ["question", 0], ["is", 0], ["pain", 0], ["experienced", 0], ["in", 0], ["a", 0], ["missing", 0], ["body", 0], ["part", 0], ["or", 0], ["paralyzed", 0], ["area", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5454545454545454, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5272727272727272, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.8059701492537313, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.7910447761194029, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5454545454545454, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5272727272727272, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.8059701492537313, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.7910447761194029, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Scotland have never advanced beyond the first round of the finals competition. They have missed out on progressing to the second round three times on goal difference: in 1974, when Brazil edged them out; in 1978, when the Netherlands progressed; and in 1982, when the USSR went through. Although Scotland have played at eight finals tournaments, they have qualified on nine occasions. The Scottish Football Association declined to participate in 1950 as Scotland were not the British champions.\nQuestion: Have scotland ever been in the world cup final?", "references": ["No"], "id": "id9490"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9490", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["scotland", 0], ["have", 0], ["never", 0], ["advanced", 0], ["beyond", 0], ["the", 0], ["first", 0], ["round", 0], ["of", 0], ["the", 0], ["finals", 0], ["competition", 0], ["they", 1], ["have", 1], ["missed", 1], ["out", 1], ["on", 1], ["progressing", 1], ["to", 1], ["the", 1], ["second", 1], ["round", 1], ["three", 0], ["times", 0], ["on", 0], ["goal", 0], ["difference", 0], ["in", 0], ["1974", 0], ["when", 0], ["brazil", 0], ["edged", 0], ["them", 0], ["out", 0], ["in", 0], ["1978", 0], ["when", 0], ["the", 0], ["netherlands", 0], ["progressed", 0], ["and", 0], ["in", 0], ["1982", 0], ["when", 0], ["the", 0], ["ussr", 0], ["went", 0], ["through", 0], ["although", 0], ["scotland", 0], ["have", 0], ["played", 0], ["at", 0], ["eight", 0], ["finals", 0], ["tournaments", 0], ["they", 0], ["have", 0], ["qualified", 0], ["on", 0], ["nine", 0], ["occasions", 0], ["the", 0], ["scottish", 0], ["football", 0], ["association", 0], ["declined", 0], ["to", 0], ["participate", 0], ["in", 0], ["1950", 0], ["as", 0], ["scotland", 0], ["were", 0], ["not", 0], ["the", 0], ["british", 0], ["champions", 0], ["question", 0], ["have", 0], ["scotland", 0], ["ever", 0], ["been", 0], ["in", 0], ["the", 0], ["world", 0], ["cup", 0], ["final", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.12987012987012986, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.12987012987012986, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.24719101123595505, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.24719101123595505, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.12987012987012986, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.12987012987012986, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.24719101123595505, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.24719101123595505, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "The Sole Survivor receives a cash prize of $1,000,000 prior to taxes and sometimes also receives a car provided by the show's sponsor. Every player receives a prize for participating on Survivor depending on how long he or she lasts in the game. In most seasons, the runner-up receives $100,000, and third place wins $85,000. All other players receive money on a sliding scale, though specific amounts have rarely been made public. Sonja Christopher, the first player voted off of Survivor: Borneo, received $2,500. In Survivor: Fiji, the first season with tied runners-up, the two runners-up received US$100,000 each, and Yau-Man Chan received US$60,000 for his fourth-place finish. All players also receive an additional $10,000 for their appearance on the reunion show.\nQuestion: Do the runners up on survivor win money?", "references": ["Yes"], "id": "id9454"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9454", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 1], ["sole", 2], ["survivor", 0], ["receives", 0], ["a", 0], ["cash", 0], ["prize", 0], ["of", 0], ["1", 0], ["000", 0], ["000", 0], ["prior", 0], ["to", 0], ["taxes", 0], ["and", 1], ["sometimes", 1], ["also", 1], ["receives", 1], ["a", 1], ["car", 1], ["provided", 1], ["by", 1], ["the", 1], ["show", 1], ["s", 1], ["sponsor", 1], ["every", 2], ["player", 2], ["receives", 2], ["a", 2], ["prize", 2], ["for", 2], ["participating", 2], ["on", 2], ["survivor", 2], ["depending", 2], ["on", 2], ["how", 2], ["long", 2], ["he", 2], ["or", 2], ["she", 2], ["lasts", 2], ["in", 2], ["the", 2], ["game", 2], ["in", 2], ["most", 2], ["seasons", 2], ["the", 2], ["runner", 2], ["up", 2], ["receives", 2], ["100", 2], ["000", 2], ["and", 2], ["third", 2], ["place", 2], ["wins", 2], ["85", 2], ["000", 2], ["all", 2], ["other", 2], ["players", 2], ["receive", 2], ["money", 2], ["on", 2], ["a", 2], ["sliding", 2], ["scale", 2], ["though", 2], ["specific", 2], ["amounts", 2], ["have", 1], ["rarely", 1], ["been", 1], ["made", 1], ["public", 1], ["sonja", 1], ["christopher", 0], ["the", 0], ["first", 0], ["player", 0], ["voted", 0], ["off", 0], ["of", 0], ["survivor", 1], ["borneo", 1], ["received", 1], ["2", 1], ["500", 1], ["in", 2], ["survivor", 2], ["fiji", 2], ["the", 2], ["first", 2], ["season", 2], ["with", 2], ["tied", 2], ["runners", 2], ["up", 2], ["the", 2], ["two", 2], ["runners", 2], ["up", 2], ["received", 2], ["us", 2], ["100", 2], ["000", 1], ["each", 1], ["and", 1], ["yau", 0], ["man", 0], ["chan", 0], ["received", 0], ["us", 0], ["60", 0], ["000", 0], ["for", 0], ["his", 0], ["fourth", 0], ["place", 1], ["finish", 1], ["all", 2], ["players", 2], ["also", 2], ["receive", 0], ["an", 0], ["additional", 0], ["10", 0], ["000", 0], ["for", 0], ["their", 0], ["appearance", 0], ["on", 0], ["the", 0], ["reunion", 0], ["show", 0], ["question", 0], ["do", 0], ["the", 0], ["runners", 0], ["up", 0], ["on", 0], ["survivor", 0], ["win", 0], ["money", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.7132352941176471, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.4632352941176471, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.9324324324324325, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.9324324324324325, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.7132352941176471, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.4632352941176471, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.9324324324324325, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.9324324324324325, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "As part of Marvel's Marvel NOW! initiative a new Deadpool ongoing series was launched, written by Brian Posehn and Gerry Duggan and illustrated by Tony Moore. He is also a member of the Thunderbolts. In the 27th issue of his new series, as part of ``All-New Marvel NOW!'', Deadpool was married for the third time. Initially a secret, his bride was revealed in the webcomic Deadpool: The Gauntlet to be Shiklah, Queen of the Undead. Deadpool also discovers that he has a daughter by the name of Eleanor from a former flame of Deadpool named Carmelita.\nQuestion: Does deadpool have a kid in the comics?", "references": ["Yes"], "id": "id9436"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9436", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["as", 1], ["part", 1], ["of", 1], ["marvel", 1], ["s", 1], ["marvel", 1], ["now", 1], ["initiative", 1], ["a", 1], ["new", 1], ["deadpool", 1], ["ongoing", 1], ["series", 1], ["was", 1], ["launched", 1], ["written", 0], ["by", 0], ["brian", 0], ["posehn", 0], ["and", 0], ["gerry", 0], ["duggan", 0], ["and", 0], ["illustrated", 0], ["by", 0], ["tony", 0], ["moore", 0], ["he", 0], ["is", 0], ["also", 0], ["a", 0], ["member", 0], ["of", 0], ["the", 0], ["thunderbolts", 0], ["in", 1], ["the", 1], ["27th", 1], ["issue", 1], ["of", 1], ["his", 1], ["new", 1], ["series", 1], ["as", 1], ["part", 1], ["of", 1], ["all", 1], ["new", 1], ["marvel", 1], ["now", 1], ["deadpool", 1], ["was", 1], ["married", 1], ["for", 1], ["the", 1], ["third", 1], ["time", 1], ["initially", 1], ["a", 1], ["secret", 1], ["his", 1], ["bride", 1], ["was", 1], ["revealed", 1], ["in", 1], ["the", 1], ["webcomic", 1], ["deadpool", 1], ["the", 1], ["gauntlet", 1], ["to", 1], ["be", 1], ["shiklah", 1], ["queen", 1], ["of", 1], ["the", 1], ["undead", 1], ["deadpool", 1], ["also", 1], ["discovers", 1], ["that", 1], ["he", 1], ["has", 1], ["a", 1], ["daughter", 1], ["by", 1], ["the", 0], ["name", 0], ["of", 0], ["eleanor", 0], ["from", 0], ["a", 0], ["former", 0], ["flame", 0], ["of", 0], ["deadpool", 0], ["named", 0], ["carmelita", 0], ["question", 0], ["does", 0], ["deadpool", 0], ["have", 0], ["a", 0], ["kid", 0], ["in", 0], ["the", 0], ["comics", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.6875, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.6875, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.8333333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.8333333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.6875, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.6875, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.8333333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.8333333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The Federal Government of the United States (U.S. Federal Government) is the national government of the United States, a federal republic in North America, composed of 50 states, one district--Washington, D.C., and several territories. The federal government is composed of three distinct branches: legislative, executive, and judicial, whose powers are vested by the U.S. Constitution in the Congress, the president, and the federal courts, respectively. The powers and duties of these branches are further defined by acts of Congress, including the creation of executive departments and courts inferior to the Supreme Court.\nQuestion: Does the united states have a federal system of government?", "references": ["Yes"], "id": "id9466"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9466", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 1], ["federal", 1], ["government", 1], ["of", 1], ["the", 1], ["united", 1], ["states", 1], ["u", 1], ["s", 1], ["federal", 1], ["government", 1], ["is", 1], ["the", 1], ["national", 1], ["government", 1], ["of", 1], ["the", 1], ["united", 0], ["states", 0], ["a", 0], ["federal", 0], ["republic", 29], ["in", 29], ["north", 29], ["america", 29], ["composed", 29], ["of", 29], ["50", 29], ["states", 29], ["one", 29], ["district", 29], ["washington", 29], ["d", 0], ["c", 0], ["and", 0], ["several", 0], ["territories", 1], ["the", 2], ["federal", 0], ["government", 0], ["is", 1], ["composed", 1], ["of", 1], ["three", 0], ["distinct", 0], ["branches", 29], ["legislative", 29], ["executive", 29], ["and", 29], ["judicial", 22], ["whose", 22], ["powers", 23], ["are", 23], ["vested", 23], ["by", 1], ["the", 1], ["u", 0], ["s", 0], ["constitution", 0], ["in", 0], ["the", 0], ["congress", 0], ["the", 0], ["president", 0], ["and", 0], ["the", 0], ["federal", 0], ["courts", 0], ["respectively", 2], ["the", 2], ["powers", 1], ["and", 1], ["duties", 1], ["of", 1], ["these", 1], ["branches", 1], ["are", 1], ["further", 1], ["defined", 1], ["by", 1], ["acts", 1], ["of", 1], ["congress", 1], ["including", 2], ["the", 0], ["creation", 0], ["of", 0], ["executive", 0], ["departments", 0], ["and", 0], ["courts", 0], ["inferior", 0], ["to", 0], ["the", 0], ["supreme", 0], ["court", 0], ["question", 0], ["does", 0], ["the", 0], ["united", 0], ["states", 0], ["have", 0], ["a", 0], ["federal", 0], ["system", 0], ["of", 0], ["government", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.625, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.40352692971695986, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.8888888888888888, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.8888888888888888, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.4166666666666667, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.3958333333333333, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.8888888888888888, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.8888888888888888, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Fantastic Beasts and Where to Find Them is a 2016 fantasy film directed by David Yates. A joint British and American production, it is a spin-off and prequel to the Harry Potter film series, and it was produced and written by J.K. Rowling in her screenwriting debut, and inspired by her 2001 book of the same name. The film stars Eddie Redmayne as Newt Scamander, with Katherine Waterston, Dan Fogler, Alison Sudol, Ezra Miller, Samantha Morton, Jon Voight, Carmen Ejogo, Ron Perlman, Colin Farrell and Johnny Depp in supporting roles. It is the first installment in the Fantastic Beasts film series, and ninth overall in the Wizarding World franchise, that began with the Harry Potter films.\nQuestion: Is fantastic beasts and where to find them a prequel?", "references": ["Yes"], "id": "id9429"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9429", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["fantastic", 7], ["beasts", 7], ["and", 7], ["where", 7], ["to", 3], ["find", 2], ["them", 2], ["is", 2], ["a", 2], ["2016", 2], ["fantasy", 2], ["film", 2], ["directed", 2], ["by", 2], ["david", 2], ["yates", 2], ["a", 2], ["joint", 2], ["british", 2], ["and", 1], ["american", 1], ["production", 1], ["it", 1], ["is", 0], ["a", 0], ["spin", 0], ["off", 0], ["and", 1], ["prequel", 1], ["to", 1], ["the", 1], ["harry", 1], ["potter", 1], ["film", 1], ["series", 1], ["and", 1], ["it", 5], ["was", 5], ["produced", 5], ["and", 5], ["written", 5], ["by", 0], ["j", 0], ["k", 0], ["rowling", 0], ["in", 0], ["her", 0], ["screenwriting", 0], ["debut", 0], ["and", 0], ["inspired", 0], ["by", 0], ["her", 0], ["2001", 0], ["book", 2], ["of", 2], ["the", 2], ["same", 2], ["name", 2], ["the", 2], ["film", 2], ["stars", 2], ["eddie", 2], ["redmayne", 2], ["as", 2], ["newt", 2], ["scamander", 2], ["with", 2], ["katherine", 4], ["waterston", 4], ["dan", 2], ["fogler", 2], ["alison", 0], ["sudol", 0], ["ezra", 0], ["miller", 0], ["samantha", 0], ["morton", 0], ["jon", 0], ["voight", 0], ["carmen", 0], ["ejogo", 0], ["ron", 0], ["perlman", 0], ["colin", 0], ["farrell", 0], ["and", 0], ["johnny", 0], ["depp", 0], ["in", 0], ["supporting", 0], ["roles", 0], ["it", 0], ["is", 0], ["the", 0], ["first", 0], ["installment", 0], ["in", 1], ["the", 1], ["fantastic", 1], ["beasts", 1], ["film", 1], ["series", 1], ["and", 1], ["ninth", 1], ["overall", 1], ["in", 0], ["the", 0], ["wizarding", 0], ["world", 0], ["franchise", 0], ["that", 0], ["began", 0], ["with", 0], ["the", 0], ["harry", 0], ["potter", 0], ["films", 0], ["question", 0], ["is", 0], ["fantastic", 0], ["beasts", 0], ["and", 0], ["where", 0], ["to", 0], ["find", 0], ["them", 0], ["a", 0], ["prequel", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5423728813559322, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.3339386602098466, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.8, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5992673992673992, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5423728813559322, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.3339386602098466, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.8, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5992673992673992, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The navel (clinically known as the umbilicus, colloquially known as the belly button, or tummy button) is a hollowed or sometimes raised area on the abdomen at the attachment site of the umbilical cord. All placental mammals have a navel.\nQuestion: Is navel and belly button the same thing?", "references": ["Yes"], "id": "id9477"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9477", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 1], ["navel", 1], ["clinically", 1], ["known", 1], ["as", 1], ["the", 1], ["umbilicus", 1], ["colloquially", 1], ["known", 1], ["as", 1], ["the", 1], ["belly", 1], ["button", 1], ["or", 1], ["tummy", 1], ["button", 1], ["is", 1], ["a", 1], ["hollowed", 1], ["or", 1], ["sometimes", 1], ["raised", 1], ["area", 1], ["on", 1], ["the", 1], ["abdomen", 1], ["at", 1], ["the", 1], ["attachment", 0], ["site", 0], ["of", 0], ["the", 0], ["umbilical", 0], ["cord", 0], ["all", 0], ["placental", 0], ["mammals", 0], ["have", 0], ["a", 0], ["navel", 0], ["question", 0], ["is", 0], ["navel", 0], ["and", 0], ["belly", 0], ["button", 0], ["the", 0], ["same", 0], ["thing", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.7368421052631579, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.7368421052631579, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.8, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.8, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.7368421052631579, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.7368421052631579, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.8, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.8, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Sanders played football primarily at cornerback, but also as a kick returner, punt returner, and occasionally wide receiver. He played in the National Football League (NFL) for the Atlanta Falcons, the San Francisco 49ers, the Dallas Cowboys, the Washington Redskins and the Baltimore Ravens, winning the Super Bowl with both the 49ers and the Cowboys. An outfielder in baseball, he played professionally for the New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants, and participated in the 1992 World Series with the Braves. He attended Florida State University, where he was recognized as a two-time All-American in football, and also played baseball and ran track.\nQuestion: Did deion sanders ever win a world series?", "references": ["No"], "id": "id9455"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9455", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["sanders", 0], ["played", 0], ["football", 0], ["primarily", 0], ["at", 0], ["cornerback", 0], ["but", 0], ["also", 0], ["as", 0], ["a", 0], ["kick", 0], ["returner", 0], ["punt", 0], ["returner", 0], ["and", 0], ["occasionally", 0], ["wide", 0], ["receiver", 0], ["he", 0], ["played", 0], ["in", 0], ["the", 0], ["national", 0], ["football", 0], ["league", 0], ["nfl", 0], ["for", 1], ["the", 2], ["atlanta", 3], ["falcons", 3], ["the", 3], ["san", 3], ["francisco", 1], ["49ers", 1], ["the", 1], ["dallas", 1], ["cowboys", 1], ["the", 1], ["washington", 1], ["redskins", 1], ["and", 1], ["the", 1], ["baltimore", 1], ["ravens", 0], ["winning", 0], ["the", 0], ["super", 0], ["bowl", 0], ["with", 0], ["both", 0], ["the", 0], ["49ers", 0], ["and", 0], ["the", 0], ["cowboys", 0], ["an", 0], ["outfielder", 0], ["in", 0], ["baseball", 0], ["he", 0], ["played", 0], ["professionally", 0], ["for", 1], ["the", 1], ["new", 1], ["york", 1], ["yankees", 0], ["the", 0], ["atlanta", 0], ["braves", 0], ["the", 0], ["cincinnati", 0], ["reds", 0], ["and", 0], ["the", 0], ["san", 0], ["francisco", 0], ["giants", 0], ["and", 0], ["participated", 0], ["in", 0], ["the", 0], ["1992", 0], ["world", 0], ["series", 0], ["with", 0], ["the", 0], ["braves", 0], ["he", 0], ["attended", 0], ["florida", 0], ["state", 0], ["university", 0], ["where", 0], ["he", 0], ["was", 0], ["recognized", 0], ["as", 0], ["a", 0], ["two", 0], ["time", 0], ["all", 0], ["american", 0], ["in", 0], ["football", 0], ["and", 0], ["also", 0], ["played", 0], ["baseball", 0], ["and", 0], ["ran", 0], ["track", 0], ["question", 0], ["did", 0], ["deion", 0], ["sanders", 0], ["ever", 0], ["win", 0], ["a", 0], ["world", 0], ["series", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.19090909090909092, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.16212121212121214, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.36885245901639346, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.36885245901639346, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.19090909090909092, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.16212121212121214, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.36885245901639346, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.36885245901639346, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "Kelly played Laurie Forman, the older sister of Eric Forman, on That '70s Show. She abruptly left the show midway through the third season, and her character was written out of the show to ``attend beauty school''. She returned to the show in the fifth season for four episodes but was replaced with Christina Moore in the sixth season. In an interview with ABC News, she admitted that ``with That '70s Show I was guilty of a drinking problem, and I ran'', blaming her alcoholism on the loss of a baby.\nQuestion: Did they change laurie in that 70s show?", "references": ["Yes"], "id": "id9489"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9489", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["kelly", 0], ["played", 0], ["laurie", 0], ["forman", 0], ["the", 0], ["older", 0], ["sister", 0], ["of", 0], ["eric", 0], ["forman", 0], ["on", 0], ["that", 0], ["70s", 0], ["show", 0], ["she", 0], ["abruptly", 0], ["left", 0], ["the", 0], ["show", 0], ["midway", 0], ["through", 0], ["the", 0], ["third", 0], ["season", 0], ["and", 0], ["her", 0], ["character", 0], ["was", 0], ["written", 0], ["out", 0], ["of", 0], ["the", 0], ["show", 0], ["to", 0], ["attend", 0], ["beauty", 0], ["school", 0], ["she", 0], ["returned", 0], ["to", 0], ["the", 0], ["show", 0], ["in", 0], ["the", 0], ["fifth", 0], ["season", 0], ["for", 0], ["four", 0], ["episodes", 0], ["but", 0], ["was", 0], ["replaced", 0], ["with", 0], ["christina", 0], ["moore", 0], ["in", 0], ["the", 0], ["sixth", 0], ["season", 0], ["in", 0], ["an", 0], ["interview", 0], ["with", 0], ["abc", 0], ["news", 0], ["she", 0], ["admitted", 0], ["that", 0], ["with", 2], ["that", 2], ["70s", 0], ["show", 0], ["i", 0], ["was", 0], ["guilty", 0], ["of", 0], ["a", 0], ["drinking", 0], ["problem", 0], ["and", 0], ["i", 0], ["ran", 0], ["blaming", 0], ["her", 0], ["alcoholism", 0], ["on", 0], ["the", 0], ["loss", 0], ["of", 0], ["a", 0], ["baby", 0], ["question", 0], ["did", 0], ["they", 0], ["change", 0], ["laurie", 0], ["in", 0], ["that", 0], ["70s", 0], ["show", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.02247191011235955, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.011235955056179775, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.13861386138613863, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.06930693069306931, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.02247191011235955, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.011235955056179775, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.13861386138613863, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.06930693069306931, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The Resident is an American medical drama television series aired by Fox Broadcasting Company that premiered on January 21, 2018, as a mid-season replacement entry in the 2017--18 television season. The fictional series focuses on the lives and duties of staff members at Chastain Park Memorial Hospital, while delving into the bureaucratic practices of the hospital industry. Formerly called The City, the show was purchased by Fox from Showtime in 2017. It was created by created by Amy Holden Jones, Hayley Schore, and Roshan Sethi. On May 10, 2017, Fox ordered a full 14-episode season and renewed the series for a second season on May 7, 2018. The first season officially concluded on May 14, 2018.\nQuestion: Is the tv show the resident over for the season?", "references": ["Yes"], "id": "id9431"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9431", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 0], ["resident", 0], ["is", 0], ["an", 0], ["american", 0], ["medical", 0], ["drama", 0], ["television", 0], ["series", 0], ["aired", 0], ["by", 0], ["fox", 0], ["broadcasting", 0], ["company", 0], ["that", 0], ["premiered", 0], ["on", 0], ["january", 0], ["21", 0], ["2018", 0], ["as", 0], ["a", 0], ["mid", 0], ["season", 0], ["replacement", 0], ["entry", 0], ["in", 0], ["the", 0], ["2017", 0], ["18", 0], ["television", 0], ["season", 0], ["the", 0], ["fictional", 0], ["series", 0], ["focuses", 1], ["on", 1], ["the", 0], ["lives", 0], ["and", 0], ["duties", 0], ["of", 0], ["staff", 0], ["members", 0], ["at", 0], ["chastain", 0], ["park", 0], ["memorial", 0], ["hospital", 0], ["while", 0], ["delving", 0], ["into", 0], ["the", 0], ["bureaucratic", 0], ["practices", 0], ["of", 0], ["the", 0], ["hospital", 0], ["industry", 0], ["formerly", 0], ["called", 0], ["the", 0], ["city", 0], ["the", 0], ["show", 0], ["was", 0], ["purchased", 0], ["by", 0], ["fox", 0], ["from", 0], ["showtime", 0], ["in", 0], ["2017", 0], ["it", 0], ["was", 0], ["created", 0], ["by", 0], ["created", 0], ["by", 0], ["amy", 0], ["holden", 0], ["jones", 0], ["hayley", 0], ["schore", 0], ["and", 0], ["roshan", 0], ["sethi", 0], ["on", 0], ["may", 0], ["10", 0], ["2017", 0], ["fox", 0], ["ordered", 0], ["a", 0], ["full", 0], ["14", 0], ["episode", 0], ["season", 0], ["and", 0], ["renewed", 0], ["the", 0], ["series", 0], ["for", 0], ["a", 0], ["second", 0], ["season", 0], ["on", 0], ["may", 0], ["7", 0], ["2018", 0], ["the", 0], ["first", 0], ["season", 0], ["officially", 0], ["concluded", 0], ["on", 0], ["may", 0], ["14", 0], ["2018", 0], ["question", 0], ["is", 0], ["the", 0], ["tv", 0], ["show", 0], ["the", 0], ["resident", 0], ["over", 0], ["for", 0], ["the", 0], ["season", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.01680672268907563, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.01680672268907563, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.10687022900763359, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.10687022900763359, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.01680672268907563, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.01680672268907563, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.10687022900763359, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.10687022900763359, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Temples, houses, bridges, and roads were destroyed. It is believed that almost all buildings in the city of Pompeii were affected. In the days after the earthquake, anarchy ruled the city, where theft and starvation plagued the survivors. In the time between 62 and the eruption in 79, some rebuilding was done, but some of the damage had still not been repaired at the time of the eruption. Although it is unknown how many, a considerable number of inhabitants moved to other cities within the Roman Empire while others remained and rebuilt.\nQuestion: Were there any survivors in the pompeii eruption?", "references": ["Yes"], "id": "id9468"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9468", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["temples", 0], ["houses", 0], ["bridges", 0], ["and", 0], ["roads", 0], ["were", 0], ["destroyed", 0], ["it", 0], ["is", 0], ["believed", 0], ["that", 0], ["almost", 0], ["all", 0], ["buildings", 0], ["in", 0], ["the", 0], ["city", 0], ["of", 0], ["pompeii", 0], ["were", 0], ["affected", 0], ["in", 0], ["the", 0], ["days", 0], ["after", 0], ["the", 0], ["earthquake", 0], ["anarchy", 0], ["ruled", 0], ["the", 0], ["city", 0], ["where", 0], ["theft", 0], ["and", 0], ["starvation", 0], ["plagued", 0], ["the", 0], ["survivors", 0], ["in", 0], ["the", 0], ["time", 0], ["between", 0], ["62", 0], ["and", 0], ["the", 0], ["eruption", 0], ["in", 0], ["79", 0], ["some", 1], ["rebuilding", 1], ["was", 1], ["done", 1], ["but", 1], ["some", 1], ["of", 1], ["the", 1], ["damage", 0], ["had", 0], ["still", 0], ["not", 0], ["been", 0], ["repaired", 0], ["at", 0], ["the", 0], ["time", 0], ["of", 0], ["the", 0], ["eruption", 0], ["although", 0], ["it", 0], ["is", 0], ["unknown", 0], ["how", 0], ["many", 0], ["a", 0], ["considerable", 0], ["number", 0], ["of", 0], ["inhabitants", 0], ["moved", 0], ["to", 0], ["other", 0], ["cities", 0], ["within", 0], ["the", 0], ["roman", 0], ["empire", 0], ["while", 0], ["others", 0], ["remained", 0], ["and", 0], ["rebuilt", 0], ["question", 0], ["were", 0], ["there", 0], ["any", 0], ["survivors", 0], ["in", 0], ["the", 0], ["pompeii", 0], ["eruption", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.08888888888888889, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.08888888888888889, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.19607843137254902, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.19607843137254902, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.08888888888888889, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.08888888888888889, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.19607843137254902, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.19607843137254902, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The Fire Tablet, formerly called the Kindle Fire, is a tablet computer developed by Amazon.com. Built with Quanta Computer, the Kindle Fire was first released in November 2011, featuring a color 7-inch multi-touch display with IPS technology and running a custom version of Google's Android operating system called Fire OS. The Kindle Fire HD followed in September 2012, and the Kindle Fire HDX in September 2013. In September 2014, when the fourth generation was introduced, the name ``Kindle'' was dropped. In September 2015, the fifth generation Fire 7 was released, followed by the sixth generation Fire HD 8, in September 2016. The seventh generation Fire 7 was released in June 2017.\nQuestion: Is a fire 7 the same as a kindle?", "references": ["Yes"], "id": "id9433"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9433", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 0], ["fire", 0], ["tablet", 0], ["formerly", 0], ["called", 0], ["the", 0], ["kindle", 0], ["fire", 0], ["is", 0], ["a", 0], ["tablet", 0], ["computer", 0], ["developed", 0], ["by", 0], ["amazon", 0], ["com", 0], ["built", 0], ["with", 0], ["quanta", 0], ["computer", 0], ["the", 0], ["kindle", 0], ["fire", 0], ["was", 0], ["first", 0], ["released", 0], ["in", 0], ["november", 0], ["2011", 0], ["featuring", 0], ["a", 0], ["color", 0], ["7", 0], ["inch", 0], ["multi", 0], ["touch", 0], ["display", 0], ["with", 0], ["ips", 0], ["technology", 0], ["and", 0], ["running", 0], ["a", 0], ["custom", 0], ["version", 0], ["of", 0], ["google", 0], ["s", 0], ["android", 0], ["operating", 0], ["system", 0], ["called", 0], ["fire", 0], ["os", 0], ["the", 1], ["kindle", 1], ["fire", 1], ["hd", 1], ["followed", 1], ["in", 1], ["september", 1], ["2012", 1], ["and", 1], ["the", 1], ["kindle", 1], ["fire", 1], ["hdx", 1], ["in", 1], ["september", 0], ["2013", 0], ["in", 0], ["september", 0], ["2014", 0], ["when", 0], ["the", 0], ["fourth", 0], ["generation", 0], ["was", 0], ["introduced", 0], ["the", 0], ["name", 0], ["kindle", 1], ["was", 1], ["dropped", 1], ["in", 1], ["september", 1], ["2015", 1], ["the", 1], ["fifth", 0], ["generation", 0], ["fire", 0], ["7", 0], ["was", 0], ["released", 0], ["followed", 0], ["by", 0], ["the", 0], ["sixth", 0], ["generation", 0], ["fire", 0], ["hd", 0], ["8", 0], ["in", 0], ["september", 0], ["2016", 0], ["the", 0], ["seventh", 0], ["generation", 0], ["fire", 0], ["7", 0], ["was", 0], ["released", 0], ["in", 0], ["june", 0], ["2017", 0], ["question", 0], ["is", 0], ["a", 0], ["fire", 0], ["7", 0], ["the", 0], ["same", 0], ["as", 0], ["a", 0], ["kindle", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.18421052631578946, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.18421052631578946, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.35714285714285715, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.35714285714285715, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.18421052631578946, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.18421052631578946, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.35714285714285715, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.35714285714285715, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "Shortly before the release of On Stranger Tides, it was reported that Disney was planning to shoot the fifth and the sixth films back-to-back, although it was later revealed that only the fifth film was in development. On March 4, 2017, director Joachim Rรธnning stated that Dead Men Tell No Tales was only the beginning of the final adventure, implying that it would not be the last film of the franchise and that a sixth film could be released.\nQuestion: Is there going to be any more pirates of the caribbean films?", "references": ["Yes"], "id": "id9485"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9485", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["shortly", 0], ["before", 0], ["the", 0], ["release", 0], ["of", 0], ["on", 0], ["stranger", 0], ["tides", 0], ["it", 0], ["was", 0], ["reported", 0], ["that", 0], ["disney", 0], ["was", 0], ["planning", 0], ["to", 0], ["shoot", 0], ["the", 0], ["fifth", 0], ["and", 0], ["the", 0], ["sixth", 0], ["films", 0], ["back", 0], ["to", 0], ["back", 0], ["although", 0], ["it", 0], ["was", 0], ["later", 0], ["revealed", 0], ["that", 0], ["only", 0], ["the", 0], ["fifth", 0], ["film", 0], ["was", 0], ["in", 0], ["development", 0], ["on", 0], ["march", 0], ["4", 0], ["2017", 0], ["director", 0], ["joachim", 0], ["rรธnning", 0], ["stated", 0], ["that", 0], ["dead", 0], ["men", 0], ["tell", 0], ["no", 0], ["tales", 0], ["was", 1], ["only", 1], ["the", 1], ["beginning", 1], ["of", 1], ["the", 1], ["final", 1], ["adventure", 1], ["implying", 1], ["that", 1], ["it", 1], ["would", 1], ["not", 1], ["be", 1], ["the", 1], ["last", 1], ["film", 0], ["of", 0], ["the", 0], ["franchise", 0], ["and", 0], ["that", 0], ["a", 0], ["sixth", 0], ["film", 0], ["could", 0], ["be", 0], ["released", 0], ["question", 0], ["is", 0], ["there", 0], ["going", 0], ["to", 0], ["be", 0], ["any", 0], ["more", 0], ["pirates", 0], ["of", 0], ["the", 0], ["caribbean", 0], ["films", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1927710843373494, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1927710843373494, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.29473684210526313, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.29473684210526313, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.1927710843373494, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.1927710843373494, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.29473684210526313, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.29473684210526313, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The Xbox One gaming console has received updates from Microsoft since its launch in 2013 that enable it to play select games from its two predecessor consoles, Xbox and Xbox 360. On June 15, 2015, backward compatibility with supported Xbox 360 games became available to eligible Xbox Preview program users with a beta update to the Xbox One system software. The dashboard update containing backward compatibility was released publicly on November 12, 2015. On October 24, 2017, another such update added games from the original Xbox library. The following is a list of all backward compatible games on Xbox One under this functionality.\nQuestion: Will all xbox 360 games work on xbox one?", "references": ["No"], "id": "id9453"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9453", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 1], ["xbox", 1], ["one", 1], ["gaming", 1], ["console", 1], ["has", 1], ["received", 1], ["updates", 1], ["from", 1], ["microsoft", 1], ["since", 1], ["its", 1], ["launch", 1], ["in", 1], ["2013", 1], ["that", 1], ["enable", 1], ["it", 1], ["to", 1], ["play", 1], ["select", 1], ["games", 1], ["from", 1], ["its", 0], ["two", 0], ["predecessor", 0], ["consoles", 0], ["xbox", 0], ["and", 0], ["xbox", 0], ["360", 0], ["on", 0], ["june", 0], ["15", 0], ["2015", 0], ["backward", 0], ["compatibility", 0], ["with", 0], ["supported", 0], ["xbox", 0], ["360", 0], ["games", 0], ["became", 0], ["available", 0], ["to", 0], ["eligible", 0], ["xbox", 0], ["preview", 0], ["program", 0], ["users", 0], ["with", 0], ["a", 0], ["beta", 0], ["update", 0], ["to", 0], ["the", 0], ["xbox", 0], ["one", 0], ["system", 0], ["software", 0], ["the", 0], ["dashboard", 0], ["update", 0], ["containing", 0], ["backward", 0], ["compatibility", 0], ["was", 0], ["released", 0], ["publicly", 0], ["on", 0], ["november", 0], ["12", 0], ["2015", 0], ["on", 0], ["october", 0], ["24", 0], ["2017", 0], ["another", 0], ["such", 0], ["update", 0], ["added", 0], ["games", 0], ["from", 0], ["the", 0], ["original", 0], ["xbox", 0], ["library", 0], ["the", 0], ["following", 0], ["is", 0], ["a", 0], ["list", 0], ["of", 0], ["all", 0], ["backward", 0], ["compatible", 0], ["games", 0], ["on", 0], ["xbox", 0], ["one", 0], ["under", 0], ["this", 0], ["functionality", 0], ["question", 0], ["will", 0], ["all", 0], ["xbox", 0], ["360", 0], ["games", 0], ["work", 0], ["on", 0], ["xbox", 0], ["one", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.22549019607843138, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.22549019607843138, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.30701754385964913, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.30701754385964913, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.22549019607843138, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.22549019607843138, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.30701754385964913, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.30701754385964913, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "The first FA Cup Final to go to extra time and a replay was the 1875 final, between the Royal Engineers and the Old Etonians. The initial tie finished 1--1 but the Royal Engineers won the replay 2--0 in normal time. The last replayed final was the 1993 FA Cup Final, when Arsenal and Sheffield Wednesday fought a 1--1 draw. The replay saw Arsenal win the FA Cup, 2--1 after extra time.\nQuestion: Can the fa cup final end in a tie?", "references": ["No"], "id": "id9474"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9474", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 0], ["first", 0], ["fa", 0], ["cup", 1], ["final", 1], ["to", 1], ["go", 1], ["to", 1], ["extra", 1], ["time", 1], ["and", 1], ["a", 1], ["replay", 1], ["was", 1], ["the", 1], ["1875", 1], ["final", 1], ["between", 0], ["the", 0], ["royal", 0], ["engineers", 0], ["and", 0], ["the", 0], ["old", 0], ["etonians", 0], ["the", 0], ["initial", 0], ["tie", 0], ["finished", 0], ["1", 0], ["1", 0], ["but", 0], ["the", 0], ["royal", 0], ["engineers", 0], ["won", 0], ["the", 0], ["replay", 0], ["2", 0], ["0", 0], ["in", 0], ["normal", 0], ["time", 0], ["the", 0], ["last", 0], ["replayed", 0], ["final", 0], ["was", 0], ["the", 0], ["1993", 0], ["fa", 0], ["cup", 0], ["final", 0], ["when", 0], ["arsenal", 0], ["and", 0], ["sheffield", 0], ["wednesday", 0], ["fought", 0], ["a", 0], ["1", 0], ["1", 0], ["draw", 0], ["the", 0], ["replay", 0], ["saw", 0], ["arsenal", 0], ["win", 0], ["the", 0], ["fa", 0], ["cup", 0], ["2", 0], ["1", 0], ["after", 0], ["extra", 0], ["time", 0], ["question", 0], ["can", 0], ["the", 0], ["fa", 0], ["cup", 0], ["final", 0], ["end", 0], ["in", 0], ["a", 0], ["tie", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.18666666666666668, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.18666666666666668, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.2988505747126437, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.2988505747126437, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.18666666666666668, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.18666666666666668, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.2988505747126437, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.2988505747126437, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "All but two of the universities in the Russell Group are part of the Sutton Trust's group of 30 highly selective universities, the Sutton Trust 30 (the absent members being Queen Mary University of London and Queen's University Belfast). The Sutton 13 group of the 13 most highly selective universities only includes one non-Russell Group member, the University of St Andrews. St Andrews was also the only non-Russell Group University in the top 10 by average UCAS tariff score of new undergraduate students in 2015--16, placing fifth with an average score of 525 (and an offer rate of 52.2%). Half of the Russell Group made offers to more than three quarter of their undergraduate applicants in 2015.\nQuestion: Is st andrews university in the russell group?", "references": ["No"], "id": "id9487"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9487", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["all", 1], ["but", 1], ["two", 1], ["of", 1], ["the", 1], ["universities", 1], ["in", 1], ["the", 1], ["russell", 1], ["group", 1], ["are", 1], ["part", 1], ["of", 1], ["the", 1], ["sutton", 1], ["trust", 1], ["s", 1], ["group", 1], ["of", 1], ["30", 1], ["highly", 1], ["selective", 1], ["universities", 1], ["the", 1], ["sutton", 1], ["trust", 1], ["30", 1], ["the", 1], ["absent", 1], ["members", 0], ["being", 0], ["queen", 0], ["mary", 0], ["university", 0], ["of", 0], ["london", 0], ["and", 0], ["queen", 0], ["s", 0], ["university", 0], ["belfast", 0], ["the", 1], ["sutton", 1], ["13", 1], ["group", 1], ["of", 1], ["the", 1], ["13", 1], ["most", 1], ["highly", 1], ["selective", 1], ["universities", 1], ["only", 0], ["includes", 0], ["one", 0], ["non", 0], ["russell", 0], ["group", 0], ["member", 0], ["the", 0], ["university", 0], ["of", 0], ["st", 0], ["andrews", 0], ["st", 1], ["andrews", 1], ["was", 1], ["also", 1], ["the", 1], ["only", 1], ["non", 1], ["russell", 1], ["group", 1], ["university", 1], ["in", 1], ["the", 1], ["top", 0], ["10", 0], ["by", 0], ["average", 0], ["ucas", 0], ["tariff", 0], ["score", 0], ["of", 0], ["new", 0], ["undergraduate", 0], ["students", 0], ["in", 0], ["2015", 0], ["16", 0], ["placing", 1], ["fifth", 1], ["with", 1], ["an", 0], ["average", 0], ["score", 0], ["of", 0], ["525", 0], ["and", 0], ["an", 0], ["offer", 0], ["rate", 0], ["of", 0], ["52", 0], ["2", 0], ["half", 1], ["of", 1], ["the", 1], ["russell", 1], ["group", 1], ["made", 1], ["offers", 0], ["to", 0], ["more", 0], ["than", 0], ["three", 0], ["quarter", 0], ["of", 0], ["their", 0], ["undergraduate", 0], ["applicants", 0], ["in", 0], ["2015", 0], ["question", 0], ["is", 0], ["st", 0], ["andrews", 0], ["university", 0], ["in", 0], ["the", 0], ["russell", 0], ["group", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5041322314049587, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.5041322314049587, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.9097744360902256, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.9097744360902256, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5041322314049587, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.5041322314049587, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.9097744360902256, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.9097744360902256, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["no", 0]], "metrics": []}}
{"instance": {"input": "As state law on waiting periods and background checks do not apply to sales by non-licensed sellers, the Florida Constitution, Art VIII Sec. 5(b), permits counties to enact ordinances that require a criminal history records check and a 3 to 5-day waiting period for non-licensed sellers when any part of a firearm sale is conducted on property to which the public has the ``right of access'', such as at a gun show conducted on public property. These local option ordinances may not be applied to holders of a concealed weapons license. Only Miami-Dade, Broward, Palm Beach, Hillsborough, and Volusia counties had enacted such ordinances.\nQuestion: Can you sell a gun privately in florida?", "references": ["Yes"], "id": "id9470"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9470", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["as", 0], ["state", 0], ["law", 0], ["on", 0], ["waiting", 0], ["periods", 0], ["and", 0], ["background", 0], ["checks", 0], ["do", 0], ["not", 0], ["apply", 0], ["to", 0], ["sales", 0], ["by", 0], ["non", 0], ["licensed", 0], ["sellers", 0], ["the", 0], ["florida", 0], ["constitution", 0], ["art", 0], ["viii", 0], ["sec", 0], ["5", 0], ["b", 0], ["permits", 0], ["counties", 0], ["to", 0], ["enact", 0], ["ordinances", 0], ["that", 0], ["require", 2], ["a", 2], ["criminal", 0], ["history", 0], ["records", 0], ["check", 0], ["and", 0], ["a", 0], ["3", 0], ["to", 0], ["5", 0], ["day", 0], ["waiting", 0], ["period", 0], ["for", 0], ["non", 0], ["licensed", 0], ["sellers", 0], ["when", 0], ["any", 0], ["part", 0], ["of", 0], ["a", 0], ["firearm", 0], ["sale", 0], ["is", 2], ["conducted", 0], ["on", 0], ["property", 0], ["to", 0], ["which", 0], ["the", 0], ["public", 0], ["has", 0], ["the", 0], ["right", 0], ["of", 0], ["access", 0], ["such", 0], ["as", 0], ["at", 0], ["a", 0], ["gun", 0], ["show", 0], ["conducted", 0], ["on", 0], ["public", 0], ["property", 0], ["these", 0], ["local", 0], ["option", 0], ["ordinances", 0], ["may", 0], ["not", 0], ["be", 0], ["applied", 0], ["to", 0], ["holders", 0], ["of", 0], ["a", 0], ["concealed", 0], ["weapons", 0], ["license", 0], ["only", 0], ["miami", 0], ["dade", 0], ["broward", 0], ["palm", 0], ["beach", 0], ["hillsborough", 0], ["and", 0], ["volusia", 0], ["counties", 0], ["had", 0], ["enacted", 0], ["such", 0], ["ordinances", 0], ["question", 0], ["can", 0], ["you", 0], ["sell", 0], ["a", 0], ["gun", 0], ["privately", 0], ["in", 0], ["florida", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.028037383177570093, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.014018691588785047, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.226890756302521, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1134453781512605, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.028037383177570093, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.014018691588785047, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.226890756302521, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.1134453781512605, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The new locks opened for commercial traffic on 26 June 2016, and the first ship to cross the canal using the third set of locks was a modern New Panamax vessel, the Chinese-owned container ship Cosco Shipping Panama. The original locks, now over 100 years old, allow engineers greater access for maintenance, and are projected to continue operating indefinitely.\nQuestion: Is the old panama canal still in use?", "references": ["Yes"], "id": "id9451"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9451", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 1], ["new", 1], ["locks", 1], ["opened", 1], ["for", 1], ["commercial", 1], ["traffic", 1], ["on", 1], ["26", 1], ["june", 1], ["2016", 1], ["and", 1], ["the", 2], ["first", 2], ["ship", 2], ["to", 2], ["cross", 2], ["the", 2], ["canal", 2], ["using", 2], ["the", 2], ["third", 2], ["set", 2], ["of", 2], ["locks", 2], ["was", 2], ["a", 2], ["modern", 0], ["new", 0], ["panamax", 0], ["vessel", 0], ["the", 0], ["chinese", 0], ["owned", 0], ["container", 0], ["ship", 0], ["cosco", 0], ["shipping", 0], ["panama", 0], ["the", 1], ["original", 1], ["locks", 1], ["now", 1], ["over", 1], ["100", 1], ["years", 1], ["old", 1], ["allow", 1], ["engineers", 0], ["greater", 0], ["access", 0], ["for", 0], ["maintenance", 0], ["and", 0], ["are", 0], ["projected", 0], ["to", 0], ["continue", 0], ["operating", 0], ["indefinitely", 0], ["question", 0], ["is", 0], ["the", 0], ["old", 0], ["panama", 0], ["canal", 0], ["still", 0], ["in", 0], ["use", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.6206896551724138, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.49137931034482757, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.8571428571428571, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.8571428571428571, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.6206896551724138, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.49137931034482757, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.8571428571428571, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.8571428571428571, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "The Handmaid's Tale is a 1990 film adaptation of Margaret Atwood's novel of the same name. Directed by Volker Schlรถndorff, the film stars Natasha Richardson (Kate/Offred), Faye Dunaway (Serena Joy), Robert Duvall (The Commander, Fred), Aidan Quinn (Nick), and Elizabeth McGovern (Moira). The screenplay was written by Harold Pinter. The original music score was composed by Ryuichi Sakamoto. MGM Home Entertainment released an Avant-Garde Cinema DVD of the film in 2001. The film was entered into the 40th Berlin International Film Festival.\nQuestion: Is there a movie the handmaid's tale?", "references": ["Yes"], "id": "id9479"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9479", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["the", 0], ["handmaid", 0], ["s", 0], ["tale", 0], ["is", 0], ["a", 0], ["1990", 0], ["film", 0], ["adaptation", 0], ["of", 0], ["margaret", 0], ["atwood", 0], ["s", 0], ["novel", 1], ["of", 1], ["the", 0], ["same", 0], ["name", 0], ["directed", 0], ["by", 0], ["volker", 0], ["schlรถndorff", 0], ["the", 0], ["film", 0], ["stars", 0], ["natasha", 0], ["richardson", 0], ["kate", 0], ["offred", 0], ["faye", 0], ["dunaway", 0], ["serena", 0], ["joy", 0], ["robert", 0], ["duvall", 0], ["the", 0], ["commander", 0], ["fred", 0], ["aidan", 0], ["quinn", 0], ["nick", 0], ["and", 0], ["elizabeth", 0], ["mcgovern", 0], ["moira", 0], ["the", 0], ["screenplay", 0], ["was", 0], ["written", 0], ["by", 0], ["harold", 0], ["pinter", 0], ["the", 0], ["original", 0], ["music", 0], ["score", 0], ["was", 0], ["composed", 0], ["by", 0], ["ryuichi", 0], ["sakamoto", 0], ["mgm", 0], ["home", 0], ["entertainment", 0], ["released", 0], ["an", 0], ["avant", 0], ["garde", 0], ["cinema", 0], ["dvd", 0], ["of", 0], ["the", 0], ["film", 0], ["in", 0], ["2001", 0], ["the", 0], ["film", 0], ["was", 0], ["entered", 0], ["into", 0], ["the", 0], ["40th", 0], ["berlin", 0], ["international", 0], ["film", 0], ["festival", 0], ["question", 0], ["is", 0], ["there", 0], ["a", 0], ["movie", 0], ["the", 0], ["handmaid", 0], ["s", 0], ["tale", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.023809523809523808, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.023809523809523808, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.14583333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.14583333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.023809523809523808, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.023809523809523808, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.14583333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.14583333333333334, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
{"instance": {"input": "MetLife Stadium is an American sports stadium located in East Rutherford, New Jersey, 8 miles outside of New York City. It is part of the Meadowlands Sports Complex and serves as the home stadium for two National Football League (NFL) franchises: the New York Giants and the New York Jets. The stadium is owned by the MetLife Stadium Company, a joint venture of the Giants and Jets, who jointly built the stadium using private funds on land owned by the New Jersey Sports and Exposition Authority. The stadium opened as New Meadowlands Stadium in 2010. In 2011, MetLife, an insurance company based in New York City, acquired the naming rights to the stadium. At a construction cost of approximately $1.6 billion, it was the most expensive stadium ever built, at the time it opened, and is the second-largest stadium in the NFL in terms of seating capacity.\nQuestion: Do the jets and giants share a stadium?", "references": ["Yes"], "id": "id9441"}, "stats_key": {"light_scenario_key": {"scenario_spec": {"class_name": "helm.benchmark.scenarios.boolq_scenario.BoolQScenario", "args": {"only_contrast": "True"}}, "split": "valid"}, "overlap_protocol_spec": {"n": 13}}, "instance_id": "id9441", "annotated_input_overlap": {"part": "input", "annotated_entry_overlap": [["metlife", 4], ["stadium", 0], ["is", 0], ["an", 0], ["american", 0], ["sports", 0], ["stadium", 0], ["located", 0], ["in", 0], ["east", 0], ["rutherford", 0], ["new", 0], ["jersey", 0], ["8", 0], ["miles", 0], ["outside", 0], ["of", 0], ["new", 0], ["york", 0], ["city", 0], ["it", 2], ["is", 2], ["part", 2], ["of", 0], ["the", 0], ["meadowlands", 0], ["sports", 0], ["complex", 0], ["and", 0], ["serves", 1], ["as", 1], ["the", 1], ["home", 1], ["stadium", 0], ["for", 0], ["two", 0], ["national", 0], ["football", 0], ["league", 0], ["nfl", 0], ["franchises", 0], ["the", 0], ["new", 0], ["york", 0], ["giants", 0], ["and", 0], ["the", 0], ["new", 0], ["york", 0], ["jets", 0], ["the", 0], ["stadium", 0], ["is", 0], ["owned", 0], ["by", 0], ["the", 0], ["metlife", 0], ["stadium", 0], ["company", 0], ["a", 0], ["joint", 0], ["venture", 0], ["of", 0], ["the", 0], ["giants", 0], ["and", 0], ["jets", 0], ["who", 0], ["jointly", 0], ["built", 0], ["the", 0], ["stadium", 0], ["using", 0], ["private", 0], ["funds", 0], ["on", 0], ["land", 0], ["owned", 0], ["by", 0], ["the", 0], ["new", 0], ["jersey", 0], ["sports", 0], ["and", 0], ["exposition", 0], ["authority", 0], ["the", 1], ["stadium", 1], ["opened", 1], ["as", 1], ["new", 1], ["meadowlands", 1], ["stadium", 1], ["in", 1], ["2010", 1], ["in", 2], ["2011", 2], ["metlife", 2], ["an", 2], ["insurance", 2], ["company", 2], ["based", 2], ["in", 2], ["new", 2], ["york", 2], ["city", 2], ["acquired", 2], ["the", 2], ["naming", 2], ["rights", 2], ["to", 2], ["the", 0], ["stadium", 0], ["at", 0], ["a", 0], ["construction", 0], ["cost", 0], ["of", 0], ["approximately", 0], ["1", 0], ["6", 0], ["billion", 0], ["it", 0], ["was", 0], ["the", 0], ["most", 0], ["expensive", 0], ["stadium", 0], ["ever", 0], ["built", 0], ["at", 0], ["the", 0], ["time", 0], ["it", 0], ["opened", 0], ["and", 1], ["is", 1], ["the", 0], ["second", 0], ["largest", 0], ["stadium", 0], ["in", 0], ["the", 0], ["nfl", 0], ["in", 0], ["terms", 0], ["of", 0], ["seating", 0], ["capacity", 0], ["question", 0], ["do", 0], ["the", 0], ["jets", 0], ["and", 0], ["giants", 0], ["share", 0], ["a", 0], ["stadium", 0], ["", 0]], "metrics": [{"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.23809523809523808, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.1683673469387755, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 0.559748427672956, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": false}}}, {"metric_score": 0.470125786163522, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 0, "weighting": true}}}, {"metric_score": 1, "metric_protocol_spec": {"partial_overlap_spec": 0, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.23809523809523808, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.1683673469387755, "metric_protocol_spec": {"partial_overlap_spec": 1, "frequency_spec": {"filter_value": 10, "weighting": true}}}, {"metric_score": 0.559748427672956, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": false}}}, {"metric_score": 0.470125786163522, "metric_protocol_spec": {"partial_overlap_spec": 2, "frequency_spec": {"filter_value": 10, "weighting": true}}}]}, "annotated_ref_overlap": {"part": "references", "annotated_entry_overlap": [["yes", 0]], "metrics": []}}
